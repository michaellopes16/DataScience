{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/michaellopes16/DataScience/blob/main/Inceptiomtime_implementation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZmVecdb9Dh-W"
      },
      "outputs": [],
      "source": [
        "#%pip install scikit-learn --upgrade --user"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "hH5fdnNF8EIt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a = 10\n",
        "print(f\"Valor da variável {a}\")"
      ],
      "metadata": {
        "id": "GFfcpHhL8LhM",
        "outputId": "8f80bdc4-7e0d-4668-903b-49a271130d4a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Valor da variável 10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CTt1zjM_q92d",
        "outputId": "d15e2113-1905-46e2-e563-9ece954a1a4d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "\n",
        "from builtins import print\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib\n",
        "import random\n",
        "\n",
        "matplotlib.use('agg')\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "matplotlib.rcParams['font.family'] = 'sans-serif'\n",
        "matplotlib.rcParams['font.sans-serif'] = 'Arial'\n",
        "\n",
        "import os\n",
        "import operator\n",
        "#import utils\n",
        "\n",
        "#from utils.constants import UNIVARIATE_DATASET_NAMES as DATASET_NAMES\n",
        "#from utils.constants import UNIVARIATE_ARCHIVE_NAMES as ARCHIVE_NAMES\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "import keras\n",
        "import tensorflow as tf \n",
        "#from utils.utils import calculate_metrics\n",
        "#from utils.utils import create_directory\n",
        "#from utils.utils import check_if_file_exits\n",
        "import gc\n",
        "import time\n",
        "\n",
        "#from utils.utils import save_logs\n",
        "#from utils.utils import save_test_duration\n",
        "\n",
        "#from utils.utils import read_all_datasets\n",
        "#from utils.utils import transform_labels\n",
        "#from utils.utils import create_directory\n",
        "#from utils.utils import run_length_xps\n",
        "#from utils.utils import generate_results_csv\n",
        "\n",
        "import sys\n",
        "import sklearn\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lhsrUO457K2C",
        "outputId": "45660571-3d41-4d05-b975-46f02e19d68e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AllCandidas_TEST.csv  AllCandidas_TRAIN.csv  AllCandidas_VAL.csv\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "os.chdir(\"/content/drive/MyDrive/Colab Notebooks/Candidas/archives/TSC/AllCandidas/\")\n",
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dDDr_FbD_oIz",
        "outputId": "aa626b8e-ea38-43db-a808-a5aa16a579b6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<_io.TextIOWrapper name='/content/drive/MyDrive/Colab Notebooks/Candidas/archives/TSC/AllCandidas/AllCandidas_TRAIN.csv' mode='r' encoding='UTF-8'>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "open(\"/content/drive/MyDrive/Colab Notebooks/Candidas/archives/TSC/AllCandidas/AllCandidas_TRAIN.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4z3uPGHKrXMC"
      },
      "outputs": [],
      "source": [
        "def check_if_file_exits(file_name):\n",
        "    return os.path.exists(file_name)\n",
        "\n",
        "\n",
        "def readucr(filename, delimiter=','):\n",
        "    print(filename)\n",
        "    data = pd.read_csv(filename, delimiter=delimiter,header=None)\n",
        "    Y = data.iloc[:, 652].values\n",
        "    X = data.iloc[:,0: 652].copy().values\n",
        "    return X, Y\n",
        "\n",
        "\n",
        "def readsits(filename, delimiter=','):\n",
        "    data = np.genfromtxt(filename, delimiter=delimiter)\n",
        "    Y = data[:, -1]\n",
        "    X = data[:, :-1]\n",
        "    return X, Y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "esRD1dQTrf1e"
      },
      "outputs": [],
      "source": [
        "def create_directory(directory_path):\n",
        "    if os.path.exists(directory_path):\n",
        "        return None\n",
        "    else:\n",
        "        try:\n",
        "            os.makedirs(directory_path)\n",
        "        except:\n",
        "            # in case another machine created the path meanwhile !:(\n",
        "            return None\n",
        "        return directory_path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yxzHJyO8rtmT"
      },
      "outputs": [],
      "source": [
        "def read_dataset(root_dir, archive_name, dataset_name):\n",
        "    datasets_dict = {}\n",
        "\n",
        "    file_name = root_dir + '/archives/' + archive_name + '/' + dataset_name + '/' + dataset_name\n",
        "    x_train, y_train = readucr(file_name + '_TRAIN.csv')\n",
        "    #Trocar aqui para teste depois \n",
        "    x_test, y_test = readucr(file_name + '_TEST.csv')\n",
        "    x_val, y_val = readucr(file_name + '_VAL.csv')\n",
        "    print(f\"x_train value:{x_train}\")\n",
        "    print(f\"y_train value:{y_train}\")\n",
        "    print(f\"x_test value:{x_test}\")\n",
        "    print(f\"y_test value:{y_test}\")\n",
        "    print(f\"x_val value:{x_val}\")\n",
        "    print(f\"y_val value:{y_val}\")\n",
        "\n",
        "    datasets_dict[dataset_name] = (x_train.copy(), y_train.copy(), x_test.copy(),\n",
        "                                   y_test.copy(), x_val.copy(),y_val.copy())\n",
        "\n",
        "    return datasets_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JB_-BQ2Sr1cg"
      },
      "outputs": [],
      "source": [
        "def read_all_datasets(root_dir, archive_name):\n",
        "    datasets_dict = {}\n",
        "\n",
        "    dataset_names_to_sort = []\n",
        "\n",
        "    if archive_name == 'TSC':\n",
        "        for dataset_name in UNIVARIATE_DATASET_NAMES:\n",
        "            root_dir_dataset = root_dir + '/archives/' + archive_name + '/' + dataset_name + '/'\n",
        "            file_name = root_dir_dataset + dataset_name\n",
        "            print(file_name)\n",
        "            x_train, y_train = readucr(file_name + '_TRAIN.csv')\n",
        "            #Trocar aqui para teste depois\n",
        "            x_test, y_test = readucr(file_name + '_TEST.csv')\n",
        "            x_val, y_val = readucr(file_name + '_VAL.csv')\n",
        "            print(f\"Valor do Xtrain no read_all_datasets {x_train}\")\n",
        "            print(f\"Valor do y_train no read_all_datasets {y_train}\")\n",
        "            datasets_dict[dataset_name] = (x_train.copy(), y_train.copy(), x_test.copy(),\n",
        "                                           y_test.copy(),x_val.copy(),y_val.copy())\n",
        "\n",
        "            dataset_names_to_sort.append((dataset_name, len(x_train)))\n",
        "\n",
        "        dataset_names_to_sort.sort(key=operator.itemgetter(1))\n",
        "\n",
        "        for i in range(len(UNIVARIATE_DATASET_NAMES)):\n",
        "            UNIVARIATE_DATASET_NAMES[i] = dataset_names_to_sort[i][0]\n",
        "    return datasets_dict"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import multilabel_confusion_matrix \n",
        "def specificity_score(y_true, y_pred):\n",
        "    cm  = multilabel_confusion_matrix(y_true, y_pred)\n",
        "    specificity = []\n",
        "    for i in range(len(cm)):\n",
        "        tn = cm[i][0][0]\n",
        "        fp = cm[i][0][1]\n",
        "        spec = tn / (tn + fp)\n",
        "        specificity.append(spec)\n",
        "    avg_specificity = sum(specificity) / len(specificity)\n",
        "    return avg_specificity"
      ],
      "metadata": {
        "id": "8E8is4aKNxBA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V9F82LTZsBen"
      },
      "outputs": [],
      "source": [
        "precision = []\n",
        "accuracy = []\n",
        "recall = []\n",
        "f1 = []\n",
        "std = 0\n",
        "\n",
        "def calculate_metrics(y_test, y_pred, duration):\n",
        "    res = pd.DataFrame(data=np.zeros((1, 7), dtype=np.double), index=[0],\n",
        "                       columns=['precision', 'accuracy', 'recall','f1_score','duration','std','specificity'])\n",
        "    temp = precision_score(y_test, y_pred, average='macro')\n",
        "    print(f\"Temp: {temp}\")\n",
        "    res['precision'] = temp\n",
        "    res['accuracy'] = accuracy_score(y_test, y_pred)\n",
        "    res['recall'] = recall_score(y_test, y_pred, average='macro')\n",
        "    res['f1_score'] = f1_score(y_test, y_pred, average='macro')\n",
        "    res['specificity'] = specificity_score(y_test, y_pred)\n",
        "    res['duration'] = duration\n",
        "    print(res)\n",
        "    return res"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7T-lY3wZsBt5"
      },
      "outputs": [],
      "source": [
        "def save_test_duration(file_name, test_duration):\n",
        "    res = pd.DataFrame(data=np.zeros((1, 1), dtype=np.double), index=[0],\n",
        "                       columns=['test_duration'])\n",
        "    res['test_duration'] = test_duration\n",
        "    res.to_csv(file_name, index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gnUIJQ5ksB75"
      },
      "outputs": [],
      "source": [
        "def transform_labels(y_train, y_test, y_val):\n",
        "    \"\"\"\n",
        "    Transform label to min equal zero and continuous\n",
        "    For example if we have [1,3,4] --->  [0,1,2]\n",
        "    \"\"\"\n",
        "    # no validation split\n",
        "    # init the encoder\n",
        "    encoder = LabelEncoder()\n",
        "    # concat train and test to fit\n",
        "    y_train_test_val = np.concatenate((y_train, y_test, y_val), axis=0)\n",
        "    # fit the encoder\n",
        "    encoder.fit(y_train_test_val)\n",
        "    # transform to min zero and continuous labels\n",
        "    new_y_train_test = encoder.transform(y_train_test_val)\n",
        "    # resplit the train and test\n",
        "    new_y_train = new_y_train_test[0:len(y_train)]\n",
        "    new_y_test = new_y_train_test[len(y_train):len(y_train)+len(y_test)]\n",
        "    new_y_val = new_y_train_test[len(y_train)+len(y_test):]\n",
        "    return new_y_train, new_y_test, new_y_val"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ApmmF3b0scMR"
      },
      "outputs": [],
      "source": [
        "def generate_results_csv(output_file_name, root_dir, clfs):\n",
        "    res = pd.DataFrame(data=np.zeros((0, 10), dtype=np.float), index=[],\n",
        "                       columns=['classifier_name', 'archive_name', 'dataset_name', 'iteration',\n",
        "                                'precision', 'accuracy', 'recall','f1_score' ,'duration','std'])\n",
        "    for archive_name in UNIVARIATE_ARCHIVE_NAMES:\n",
        "        datasets_dict = read_all_datasets(root_dir, archive_name)\n",
        "        for classifier_name in clfs:\n",
        "            durr = 0.0\n",
        "\n",
        "            curr_archive_name = archive_name\n",
        "            for dataset_name in datasets_dict.keys():\n",
        "                output_dir = root_dir + '/results/' + classifier_name + '/' \\\n",
        "                             + curr_archive_name + '/' + dataset_name + '/' + 'df_metrics.csv'\n",
        "                #print(output_dir)\n",
        "                if not os.path.exists(output_dir):\n",
        "                    continue\n",
        "                df_metrics = pd.read_csv(output_dir)\n",
        "                df_metrics['classifier_name'] = classifier_name\n",
        "                df_metrics['archive_name'] = archive_name\n",
        "                df_metrics['dataset_name'] = dataset_name\n",
        "                df_metrics['iteration'] = 0\n",
        "                res = pd.concat((res, df_metrics), axis=0, sort=False)\n",
        "                durr += df_metrics['duration'][0]\n",
        "\n",
        "    res.to_csv(root_dir + output_file_name, index=False)\n",
        "\n",
        "    res = res.loc[res['classifier_name'].isin(clfs)]\n",
        "\n",
        "    return res"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lYAf8aF9scW0"
      },
      "outputs": [],
      "source": [
        "def plot_epochs_metric(hist, file_name, metric='loss'):\n",
        "    plt.figure()\n",
        "    plt.plot(hist.history[metric])\n",
        "    plt.plot(hist.history['val_' + metric])\n",
        "    plt.title('model ' + metric)\n",
        "    plt.ylabel(metric, fontsize='large')\n",
        "    plt.xlabel('epoch', fontsize='large')\n",
        "    plt.legend(['train', 'val'], loc='upper left')\n",
        "    plt.savefig(file_name, bbox_inches='tight')\n",
        "    plt.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8CyqisiEscgC"
      },
      "outputs": [],
      "source": [
        "def save_logs(output_directory, hist, y_pred, y_test, duration,\n",
        "              lr=True, plot_test_acc=True):\n",
        "    hist_df = pd.DataFrame(hist.history)\n",
        "    #2 * (Precision * Recall) / (Precision + Recall)\n",
        "    print(\"Histórico\")\n",
        "    print(hist_df)\n",
        "    hist_df['f1'] = 2 * ((hist_df.iloc[:, 3] * hist_df.iloc[:, 2])/(hist_df.iloc[:, 3] + hist_df.iloc[:, 2]))\n",
        "    hist_df.to_csv(output_directory + 'history.csv', index=False)\n",
        "\n",
        "    df_metrics = calculate_metrics(y_test, y_pred, duration)\n",
        "    precision.append(df_metrics['precision'])\n",
        "    accuracy.append(df_metrics['accuracy'])\n",
        "    recall.append(df_metrics['recall'])\n",
        "    f1.append(df_metrics['f1_score'])\n",
        "\n",
        "    df_metrics.to_csv(output_directory + 'df_metrics_val.csv', index=False)\n",
        "\n",
        "    index_best_model = hist_df['loss'].idxmin()\n",
        "    row_best_model = hist_df.loc[index_best_model]\n",
        "\n",
        "    df_best_model = pd.DataFrame(data=np.zeros((1, 6), dtype=np.float), index=[0],\n",
        "                                 columns=['best_model_train_loss', 'best_model_val_loss', 'best_model_train_acc',\n",
        "                                          'best_model_val_acc', 'best_model_learning_rate', 'best_model_nb_epoch'])\n",
        "\n",
        "    df_best_model['best_model_train_loss'] = row_best_model['loss']\n",
        "    #if plot_test_acc:\n",
        "    #    df_best_model['best_model_val_loss'] = row_best_model['val_loss']\n",
        "    #df_best_model['best_model_train_acc'] = row_best_model['acc']\n",
        "    if plot_test_acc:\n",
        "        df_best_model['best_model_val_acc'] = row_best_model['val_acc']\n",
        "    if lr == True:\n",
        "        df_best_model['best_model_learning_rate'] = row_best_model['lr']\n",
        "    df_best_model['best_model_nb_epoch'] = index_best_model\n",
        "\n",
        "    df_best_model.to_csv(output_directory + 'df_best_model.csv', index=False)\n",
        "\n",
        "    if plot_test_acc:\n",
        "        # plot losses\n",
        "        plot_epochs_metric(hist, output_directory + 'epochs_loss.png')\n",
        "\n",
        "    return df_metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J9uNdVgzs1mo"
      },
      "outputs": [],
      "source": [
        "def create_synthetic_dataset(pattern_len=[0.25], pattern_pos=[0.1, 0.65], ts_len=128, ts_n=128):\n",
        "    random.seed(1234)\n",
        "    np.random.seed(1234)\n",
        "\n",
        "    nb_classes = len(pattern_pos) * len(pattern_len)\n",
        "\n",
        "    out_dir = '/b/home/uha/hfawaz-datas/dl-tsc/archives/UCRArchive_2018/BinaryData/'\n",
        "\n",
        "    create_directory(out_dir)\n",
        "\n",
        "    x_train = np.random.normal(0.0, 0.1, size=(ts_n, ts_len))\n",
        "    x_test = np.random.normal(0.0, 0.1, size=(ts_n, ts_len))\n",
        "\n",
        "    y_train = np.random.randint(low=0, high=nb_classes, size=(ts_n,))\n",
        "    y_test = np.random.randint(low=0, high=nb_classes, size=(ts_n,))\n",
        "\n",
        "    # make sure at least each class has one example\n",
        "    y_train[:nb_classes] = np.arange(start=0, stop=nb_classes, dtype=np.int32)\n",
        "    y_test[:nb_classes] = np.arange(start=0, stop=nb_classes, dtype=np.int32)\n",
        "\n",
        "    # each class is defined with a certain combination of pattern_pos and pattern_len\n",
        "    # with one pattern_len and two pattern_pos we can create only two classes\n",
        "    # example:  class 0 _____-_  & class 1 _-_____\n",
        "\n",
        "    # create the class definitions\n",
        "    class_def = [None for i in range(nb_classes)]\n",
        "\n",
        "    idx_class = 0\n",
        "    for pl in pattern_len:\n",
        "        for pp in pattern_pos:\n",
        "            class_def[idx_class] = {'pattern_len': int(pl * ts_len),\n",
        "                                    'pattern_pos': int(pp * ts_len)}\n",
        "            idx_class += 1\n",
        "\n",
        "    # create the dataset\n",
        "    for i in range(ts_n):\n",
        "        # for the train\n",
        "        c = y_train[i]\n",
        "        curr_pattern_pos = class_def[c]['pattern_pos']\n",
        "        curr_pattern_len = class_def[c]['pattern_len']\n",
        "        x_train[i][curr_pattern_pos:curr_pattern_pos + curr_pattern_len] = \\\n",
        "            x_train[i][curr_pattern_pos:curr_pattern_pos + curr_pattern_len] + 1.0\n",
        "\n",
        "        # for the test\n",
        "        c = y_test[i]\n",
        "        curr_pattern_pos = class_def[c]['pattern_pos']\n",
        "        curr_pattern_len = class_def[c]['pattern_len']\n",
        "        x_test[i][curr_pattern_pos:curr_pattern_pos + curr_pattern_len] = \\\n",
        "            x_test[i][curr_pattern_pos:curr_pattern_pos + curr_pattern_len] + 1.0\n",
        "\n",
        "    # znorm\n",
        "    x_train = (x_train - x_train.mean(axis=1, keepdims=True)) \\\n",
        "              / x_train.std(axis=1, keepdims=True)\n",
        "\n",
        "    x_test = (x_test - x_test.mean(axis=1, keepdims=True)) \\\n",
        "             / x_test.std(axis=1, keepdims=True)\n",
        "\n",
        "    # visualize example\n",
        "    # plt.figure()\n",
        "    # colors = generate_array_of_colors(nb_classes)\n",
        "    # for c in range(nb_classes):\n",
        "    #     plt.plot(x_train[y_train == c][0], color=colors[c], label='class-' + str(c))\n",
        "    # plt.legend(loc='best')\n",
        "    # plt.savefig('out.pdf')\n",
        "    # exit()\n",
        "\n",
        "    # np.save(out_dir+'x_train.npy',x_train)\n",
        "    # np.save(out_dir+'y_train.npy',y_train)\n",
        "    # np.save(out_dir+'x_test.npy',x_test)\n",
        "    # np.save(out_dir+'y_test.npy',y_test)\n",
        "\n",
        "    # print('Done creating dataset!')\n",
        "\n",
        "    return x_train, y_train, x_test, y_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sPgcX9m4s1sK"
      },
      "outputs": [],
      "source": [
        "def generate_array_of_colors(n):\n",
        "    # https://www.quora.com/How-do-I-generate-n-visually-distinct-RGB-colours-in-Python\n",
        "    ret = []\n",
        "    r = int(random.random() * 256)\n",
        "    g = int(random.random() * 256)\n",
        "    b = int(random.random() * 256)\n",
        "    alpha = 1.0\n",
        "    step = 256 / n\n",
        "    for i in range(n):\n",
        "        r += step\n",
        "        g += step\n",
        "        b += step\n",
        "        r = int(r) % 256\n",
        "        g = int(g) % 256\n",
        "        b = int(b) % 256\n",
        "        ret.append((r / 255, g / 255, b / 255, alpha))\n",
        "    return ret"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7WRYP7qfs1x4"
      },
      "outputs": [],
      "source": [
        "# def read_sits_xps(root_dir):\n",
        "#     datasets_dict = {}\n",
        "#     path_to_data = root_dir + 'archives/SITS/resampled-SITS/'\n",
        "#     path_to_test = root_dir + 'archives/SITS/' + 'SatelliteFull_TEST_1000.csv'\n",
        "\n",
        "#     x_test, y_test = readsits(path_to_test)\n",
        "\n",
        "#     for subdir, dirs, files in os.walk(path_to_data):\n",
        "#         for file_name in files:\n",
        "#             arr = file_name.split('.')\n",
        "#             dataset_name = arr[0]\n",
        "#             file_type = arr[1]\n",
        "#             if file_type == 'csv':\n",
        "#                 x_train, y_train = readsits(subdir + '/' + file_name)\n",
        "\n",
        "#                 datasets_dict[dataset_name] = (x_train.copy(), y_train.copy(), x_test.copy(),\n",
        "#                                                y_test.copy())\n",
        "\n",
        "#     return datasets_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ckLDgRLzs17H"
      },
      "outputs": [],
      "source": [
        "def resample_dataset(x, rate):\n",
        "    new_x = np.zeros(shape=(x.shape[0], rate))\n",
        "    from scipy import signal\n",
        "    for i in range(x.shape[0]):\n",
        "        f = signal.resample(x[0], rate)\n",
        "        new_x[i] = f\n",
        "    return new_x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GApt7T0MtRF2"
      },
      "outputs": [],
      "source": [
        "def run_length_xps(root_dir):\n",
        "    #archive_name = ARCHIVE_NAMES[0]\n",
        "    archive_name = UNIVARIATE_ARCHIVE_NAMES[0]\n",
        "    dataset_name = 'InlineSkate'\n",
        "    datasets_dict = read_dataset(root_dir, archive_name, dataset_name)\n",
        "\n",
        "    lengths = [2 ** i for i in range(5, 12)]\n",
        "\n",
        "    x_train = datasets_dict[dataset_name][0]\n",
        "    y_train = datasets_dict[dataset_name][1]\n",
        "    x_test = datasets_dict[dataset_name][2]\n",
        "    y_test = datasets_dict[dataset_name][3]\n",
        "    x_val = datasets_dict[dataset_name][4]\n",
        "    y_val = datasets_dict[dataset_name][5]\n",
        "\n",
        "    new_archive_name = 'TSC'\n",
        "#    new_archive_name = 'InlineSkateXPs'\n",
        "\n",
        "    for l in lengths:\n",
        "        new_x_train = resample_dataset(x_train, l)\n",
        "        new_x_test = resample_dataset(x_test, l)\n",
        "        new_x_val = resample_dataset(x_val, l)\n",
        "        new_dataset_name = dataset_name + '-' + str(l)\n",
        "        new_dataset_dir = root_dir + 'archives/' + new_archive_name + '/' + new_dataset_name + '/'\n",
        "        create_directory(new_dataset_dir)\n",
        "\n",
        "        np.save(new_dataset_dir + 'x_train.npy', new_x_train)\n",
        "        np.save(new_dataset_dir + 'y_train.npy', y_train)\n",
        "        np.save(new_dataset_dir + 'x_test.npy', new_x_test)\n",
        "        np.save(new_dataset_dir + 'y_test.npy', y_test)\n",
        "        np.save(new_dataset_dir + 'x_val.npy', new_x_val)\n",
        "        np.save(new_dataset_dir + 'y_val.npy', y_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A1yznVGrtRT4"
      },
      "outputs": [],
      "source": [
        "UNIVARIATE_DATASET_NAMES = ['AllCandidas']\n",
        "\n",
        "UNIVARIATE_ARCHIVE_NAMES = ['TSC', 'InlineSkateXPs', 'SITS']\n",
        "\n",
        "SITS_DATASETS = ['SatelliteFull_TRAIN_c301', 'SatelliteFull_TRAIN_c200', 'SatelliteFull_TRAIN_c451',\n",
        "                 'SatelliteFull_TRAIN_c89', 'SatelliteFull_TRAIN_c677', 'SatelliteFull_TRAIN_c59',\n",
        "                 'SatelliteFull_TRAIN_c133']\n",
        "\n",
        "InlineSkateXPs_DATASETS = ['InlineSkate-32', 'InlineSkate-64', 'InlineSkate-128',\n",
        "                           'InlineSkate-256', 'InlineSkate-512', 'InlineSkate-1024',\n",
        "                           'InlineSkate-2048']\n",
        "\n",
        "dataset_names_for_archive = {'TSC': UNIVARIATE_DATASET_NAMES,\n",
        "                             'SITS': SITS_DATASETS,\n",
        "                             'InlineSkateXPs': InlineSkateXPs_DATASETS}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PLqd9yE9q0cw"
      },
      "outputs": [],
      "source": [
        "class Classifier_NNE:\n",
        "\n",
        "    def create_classifier(self, model_name, input_shape, nb_classes, output_directory, verbose=False,\n",
        "                          build=True):\n",
        "        if self.check_if_match('inception*', model_name):\n",
        "            #from classifiers import inception\n",
        "            return Classifier_INCEPTION(output_directory, input_shape, nb_classes, verbose,build=build)\n",
        "\n",
        "    def check_if_match(self, rex, name2):\n",
        "        import re\n",
        "        pattern = re.compile(rex)\n",
        "        return pattern.match(name2)\n",
        "\n",
        "    def __init__(self, output_directory, input_shape, nb_classes, verbose=False, nb_iterations=5,\n",
        "                 clf_name='inception'):\n",
        "        self.classifiers = [clf_name]\n",
        "        out_add = ''\n",
        "        for cc in self.classifiers:\n",
        "            out_add = out_add + cc + '-'\n",
        "        self.archive_name = UNIVARIATE_ARCHIVE_NAMES[0]\n",
        "        self.iterations_to_take = [i for i in range(nb_iterations)]\n",
        "        for cc in self.iterations_to_take:\n",
        "            out_add = out_add + str(cc) + '-'\n",
        "        self.output_directory = output_directory.replace('nne',\n",
        "                                                         'nne' + '/' + out_add)\n",
        "        create_directory(self.output_directory)\n",
        "        self.dataset_name = output_directory.split('/')[-2]\n",
        "        self.verbose = verbose\n",
        "        self.models_dir = output_directory.replace('nne', 'classifier')\n",
        "\n",
        "    def fit(self, x_train, y_train, x_test, y_test, y_true):\n",
        "        # no training since models are pre-trained\n",
        "        start_time = time.time()\n",
        "\n",
        "        y_pred = np.zeros(shape=y_test.shape)\n",
        "\n",
        "        ll = 0\n",
        "\n",
        "        # loop through all classifiers\n",
        "        for model_name in self.classifiers:\n",
        "            # loop through different initialization of classifiers\n",
        "            for itr in self.iterations_to_take:\n",
        "                if itr == 0:\n",
        "                    itr_str = ''\n",
        "                else:\n",
        "                    itr_str = '_itr_' + str(itr)\n",
        "\n",
        "                curr_archive_name = self.archive_name + itr_str\n",
        "\n",
        "                curr_dir = self.models_dir.replace('classifier', model_name).replace(\n",
        "                    self.archive_name, curr_archive_name)\n",
        "\n",
        "                model = self.create_classifier(model_name, None, None,\n",
        "                                               curr_dir, build=False)\n",
        "\n",
        "                predictions_file_name = curr_dir + 'y_pred.npy'\n",
        "                # check if predictions already made\n",
        "                if check_if_file_exits(predictions_file_name):\n",
        "                    # then load only the predictions from the file\n",
        "                    curr_y_pred = np.load(predictions_file_name)\n",
        "                else:\n",
        "                    # then compute the predictions\n",
        "                    curr_y_pred = model.predict(x_test, y_true, x_train, y_train, y_test,\n",
        "                                                return_df_metrics=False)\n",
        "                    keras.backend.clear_session()\n",
        "\n",
        "                    np.save(predictions_file_name, curr_y_pred)\n",
        "\n",
        "                y_pred = y_pred + curr_y_pred\n",
        "\n",
        "                ll += 1\n",
        "\n",
        "        # average predictions\n",
        "        y_pred = y_pred / ll\n",
        "\n",
        "        # save predictions\n",
        "        np.save(self.output_directory + 'y_pred.npy', y_pred)\n",
        "\n",
        "        # convert the predicted from binary to integer\n",
        "        y_pred = np.argmax(y_pred, axis=1)\n",
        "\n",
        "        duration = time.time() - start_time\n",
        "\n",
        "        df_metrics = calculate_metrics(y_test, y_pred, duration)\n",
        "\n",
        "        df_metrics.to_csv(self.output_directory + 'df_metrics_val.csv', index=False)\n",
        "\n",
        "        gc.collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UdNdNnM4tSUq"
      },
      "outputs": [],
      "source": [
        "class Classifier_INCEPTION:\n",
        "\n",
        "    def __init__(self, output_directory, input_shape, nb_classes, verbose=False, build=True, batch_size=64,\n",
        "                 nb_filters=32, use_residual=True, use_bottleneck=True, depth=6, kernel_size=41, nb_epochs=1500):\n",
        "\n",
        "        self.output_directory = output_directory\n",
        "\n",
        "        self.nb_filters = nb_filters\n",
        "        self.use_residual = use_residual\n",
        "        self.use_bottleneck = use_bottleneck\n",
        "        self.depth = depth\n",
        "        self.kernel_size = kernel_size - 1\n",
        "        self.callbacks = None\n",
        "        self.batch_size = batch_size\n",
        "        self.bottleneck_size = 32\n",
        "        self.nb_epochs = nb_epochs\n",
        "\n",
        "        if build == True:\n",
        "            self.model = self.build_model(input_shape, nb_classes)\n",
        "            if (verbose == True):\n",
        "                self.model.summary()\n",
        "            self.verbose = verbose\n",
        "            self.model.save_weights(self.output_directory + 'model_init.hdf5')\n",
        "\n",
        "    def _inception_module(self, input_tensor, stride=1, activation='linear'):\n",
        "\n",
        "        if self.use_bottleneck and int(input_tensor.shape[-1]) > 1:\n",
        "            input_inception = keras.layers.Conv1D(filters=self.bottleneck_size, kernel_size=1,\n",
        "                                                  padding='same', activation=activation, use_bias=False)(input_tensor)\n",
        "        else:\n",
        "            input_inception = input_tensor\n",
        "\n",
        "        # kernel_size_s = [3, 5, 8, 11, 17]\n",
        "        kernel_size_s = [self.kernel_size // (2 ** i) for i in range(3)]\n",
        "\n",
        "        conv_list = []\n",
        "\n",
        "        for i in range(len(kernel_size_s)):\n",
        "            conv_list.append(keras.layers.Conv1D(filters=self.nb_filters, kernel_size=kernel_size_s[i],\n",
        "                                                 strides=stride, padding='same', activation=activation, use_bias=False)(\n",
        "                input_inception))\n",
        "\n",
        "        max_pool_1 = keras.layers.MaxPool1D(pool_size=3, strides=stride, padding='same')(input_tensor)\n",
        "\n",
        "        conv_6 = keras.layers.Conv1D(filters=self.nb_filters, kernel_size=1,\n",
        "                                     padding='same', activation=activation, use_bias=False)(max_pool_1)\n",
        "\n",
        "        conv_list.append(conv_6)\n",
        "\n",
        "        x = keras.layers.Concatenate(axis=2)(conv_list)\n",
        "        x = keras.layers.BatchNormalization()(x)\n",
        "        x = keras.layers.Activation(activation='relu')(x)\n",
        "        return x\n",
        "\n",
        "    def _shortcut_layer(self, input_tensor, out_tensor):\n",
        "        shortcut_y = keras.layers.Conv1D(filters=int(out_tensor.shape[-1]), kernel_size=1,\n",
        "                                         padding='same', use_bias=False)(input_tensor)\n",
        "        shortcut_y = keras.layers.BatchNormalization()(shortcut_y)\n",
        "\n",
        "        x = keras.layers.Add()([shortcut_y, out_tensor])\n",
        "        x = keras.layers.Activation('relu')(x)\n",
        "        return x\n",
        "\n",
        "    def build_model(self, input_shape, nb_classes):\n",
        "        input_layer = keras.layers.Input(input_shape)\n",
        "\n",
        "        x = input_layer\n",
        "        input_res = input_layer\n",
        "\n",
        "        for d in range(self.depth):\n",
        "\n",
        "            x = self._inception_module(x)\n",
        "\n",
        "            if self.use_residual and d % 3 == 2:\n",
        "                x = self._shortcut_layer(input_res, x)\n",
        "                input_res = x\n",
        "\n",
        "        gap_layer = keras.layers.GlobalAveragePooling1D()(x)\n",
        "\n",
        "        output_layer = keras.layers.Dense(nb_classes, activation='softmax')(gap_layer)\n",
        "\n",
        "        model = keras.models.Model(inputs=input_layer, outputs=output_layer)\n",
        "\n",
        "        model.compile(loss='categorical_crossentropy', optimizer=tf.keras.optimizers.Adam(),\n",
        "                      metrics= [\n",
        "                                tf.keras.metrics.CategoricalAccuracy(name='accuracy', dtype=None),\n",
        "                                tf.keras.metrics.Recall(),\n",
        "                                tf.keras.metrics.Precision(),\n",
        "                                tf.keras.metrics.TruePositives(),\n",
        "                                tf.keras.metrics.TrueNegatives(),\n",
        "                                tf.keras.metrics.FalsePositives(),\n",
        "                                tf.keras.metrics.FalseNegatives()\n",
        "                                ])\n",
        " \n",
        "        reduce_lr = keras.callbacks.ReduceLROnPlateau(monitor='loss', factor=0.5, patience=50,\n",
        "                                                      min_lr=0.0001)\n",
        "\n",
        "        file_path = self.output_directory + 'best_model.hdf5'\n",
        "\n",
        "        model_checkpoint = keras.callbacks.ModelCheckpoint(filepath=file_path, monitor='loss',\n",
        "                                                           save_best_only=True)\n",
        "\n",
        "        self.callbacks = [reduce_lr, model_checkpoint]\n",
        "\n",
        "        return model\n",
        "\n",
        "    def fit(self, x_train, y_train, x_val, y_val, y_true, plot_test_acc=False):\n",
        "        #if len(keras.backend.tensorflow_backend._get_available_gpus()) == 0:       \n",
        "        #    print('error no gpu')\n",
        "        #    exit()\n",
        "        # x_val and y_val are only used to monitor the test loss and NOT for training\n",
        "        print(\"Dentro do FitModel\")\n",
        "        if self.batch_size is None:\n",
        "            mini_batch_size = int(min(x_train.shape[0] / 10, 16))\n",
        "        else:\n",
        "            mini_batch_size = self.batch_size\n",
        "\n",
        "        start_time = time.time()\n",
        "\n",
        "        if plot_test_acc:\n",
        "\n",
        "            hist = self.model.fit(x_train, y_train, batch_size=mini_batch_size, epochs=self.nb_epochs,\n",
        "                                  verbose=self.verbose, validation_data=(x_val, y_val), callbacks=self.callbacks)\n",
        "        else:\n",
        "\n",
        "            hist = self.model.fit(x_train, y_train, batch_size=mini_batch_size, epochs=self.nb_epochs,\n",
        "                                  verbose=self.verbose, callbacks=self.callbacks)\n",
        "\n",
        "        duration = time.time() - start_time\n",
        "\n",
        "        self.model.save(self.output_directory + 'last_model.hdf5')\n",
        "\n",
        "        y_pred = self.predict(x_val, y_true, x_train, y_train, y_val,\n",
        "                              return_df_metrics=False)\n",
        "\n",
        "        # save predictions\n",
        "        np.save(self.output_directory + 'y_pred.npy', y_pred)\n",
        "         # save predictions\n",
        "        np.save(self.output_directory + 'y_true.npy', y_true)\n",
        "\n",
        "        # convert the predicted from binary to integer\n",
        "        print(f\"y_pred before save =  \\n {y_pred}\")\n",
        "        y_pred = np.argmax(y_pred, axis=1)\n",
        "\n",
        "        df_metrics = save_logs(self.output_directory, hist, y_pred, y_true, duration,\n",
        "                               plot_test_acc=plot_test_acc)\n",
        "\n",
        "        keras.backend.clear_session()\n",
        "\n",
        "        return df_metrics\n",
        "\n",
        "    def predict(self, x_test, y_true, x_train, y_train, y_test, return_df_metrics=True):\n",
        "        start_time = time.time()\n",
        "        model_path = self.output_directory + 'best_model.hdf5'\n",
        "        model = keras.models.load_model(model_path)\n",
        "        y_pred = model.predict(x_test, batch_size=self.batch_size)\n",
        "        if return_df_metrics:\n",
        "            y_pred = np.argmax(y_pred, axis=1)\n",
        "            df_metrics = calculate_metrics(y_test, y_pred, 0.0)\n",
        "            return df_metrics\n",
        "        else:\n",
        "            test_duration = time.time() - start_time\n",
        "            save_test_duration(self.output_directory + 'test_duration.csv', test_duration)\n",
        "            return y_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "80oEFjNvtR-C"
      },
      "outputs": [],
      "source": [
        "def prepare_data():\n",
        "    x_train = datasets_dict[dataset_name][0]\n",
        "    y_train = datasets_dict[dataset_name][1]\n",
        "    x_test = datasets_dict[dataset_name][2]\n",
        "    y_test = datasets_dict[dataset_name][3]\n",
        "    x_val = datasets_dict[dataset_name][4]\n",
        "    y_val = datasets_dict[dataset_name][5]        \n",
        "    print(f\"valor de x_train no prepare data {x_train}\")\n",
        "    print(f\"valor de y_train no prepare data {y_train}\")\n",
        "    print(f\"valor de y_val no prepare data {y_val}\")\n",
        "    nb_classes = len(np.unique(np.concatenate((y_train, y_test,y_val ), axis=0)))\n",
        "\n",
        "    # make the min to zero of labels\n",
        "    y_train, y_test, y_val = transform_labels(y_train, y_test, y_val)\n",
        "\n",
        "    # save orignal y because later we will use binary\n",
        "    y_true = y_test.astype(np.int64)\n",
        "    y_true_train = y_train.astype(np.int64)\n",
        "    y_true_val = y_val.astype(np.int64)\n",
        "    # transform the labels from integers to one hot vectors\n",
        "    enc = sklearn.preprocessing.OneHotEncoder()\n",
        "    enc.fit(np.concatenate((y_train, y_test,y_val), axis=0).reshape(-1, 1))\n",
        "    y_train = enc.transform(y_train.reshape(-1, 1)).toarray()\n",
        "    y_test = enc.transform(y_test.reshape(-1, 1)).toarray()\n",
        "    y_val = enc.transform(y_val.reshape(-1, 1)).toarray()\n",
        "\n",
        "    if len(x_train.shape) == 2:  # if univariate\n",
        "        # add a dimension to make it multivariate with one dimension\n",
        "        x_train = x_train.reshape((x_train.shape[0], x_train.shape[1], 1))\n",
        "        x_test = x_test.reshape((x_test.shape[0], x_test.shape[1], 1))\n",
        "        x_val = x_val.reshape((x_val.shape[0], x_val.shape[1], 1))\n",
        "\n",
        "    return x_train, y_train, x_test, y_test, x_test, x_val, y_val, y_true, nb_classes, y_true_train, enc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AyhMePQgyywk"
      },
      "outputs": [],
      "source": [
        "def fit_classifier():\n",
        "    input_shape = x_train.shape[1:]\n",
        "\n",
        "    classifier = create_classifier(classifier_name, input_shape, nb_classes,\n",
        "                                   output_directory)\n",
        "\n",
        "    classifier.fit(x_train, y_train, x_test, y_test, y_true)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h_qBGd3dzDjg"
      },
      "outputs": [],
      "source": [
        "def create_classifier(classifier_name, input_shape, nb_classes, output_directory,\n",
        "                      verbose=False, build=True):\n",
        "    if classifier_name == 'nne':\n",
        "        #from classifiers import nne\n",
        "        return Classifier_NNE(output_directory, input_shape, nb_classes, verbose)\n",
        "\n",
        "    if classifier_name == 'inception':\n",
        "        #from classifiers import inception\n",
        "        return Classifier_INCEPTION(output_directory, input_shape, nb_classes,\n",
        "                                    verbose, build=build)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nbk-HPHpzDw3"
      },
      "outputs": [],
      "source": [
        "def get_xp_val(xp):\n",
        "    if xp == 'batch_size':\n",
        "        xp_arr = [16, 32, 128]\n",
        "    elif xp == 'use_bottleneck':\n",
        "        xp_arr = [False]\n",
        "    elif xp == 'use_residual':\n",
        "        xp_arr = [False]\n",
        "    elif xp == 'nb_filters':\n",
        "        xp_arr = [16, 64]\n",
        "    elif xp == 'depth':\n",
        "        xp_arr = [3, 9]\n",
        "    elif xp == 'kernel_size':\n",
        "        xp_arr = [8, 64]\n",
        "    else:\n",
        "        raise Exception('wrong argument')\n",
        "    return xp_arr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rKy73uyc_smT"
      },
      "outputs": [],
      "source": [
        "############################################### main\n",
        "\n",
        "#root_dir = '/b/home/uha/hfawaz-datas/temp-dl-tsc/'\n",
        "\n",
        "root_dir = '/content/drive/MyDrive/Colab Notebooks/Candidas'\n",
        "\n",
        "xps = ['use_bottleneck', 'use_residual', 'nb_filters', 'depth',\n",
        "       'kernel_size', 'batch_size']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z2cjLDVFJchw"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o-YSk5I-JbdP"
      },
      "outputs": [],
      "source": [
        "# device_name = tf.test.gpu_device_name()\n",
        "# if device_name != '/device:GPU:0':\n",
        "#   raise SystemError('GPU device not found')\n",
        "# print('Found GPU at: {}'.format(device_name))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L-VpDwoYJk38"
      },
      "outputs": [],
      "source": [
        "# device_name = tf.test.gpu_device_name()\n",
        "# if device_name != '/device:GPU:0':\n",
        "#   print(\n",
        "#       '\\n\\nThis error most likely means that this notebook is not '\n",
        "#       'configured to use a GPU.  Change this in Notebook Settings via the '\n",
        "#       'command palette (cmd/ctrl-shift-P) or the Edit menu.\\n\\n')\n",
        "#   raise SystemError('GPU device not found')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c78wadTW_uJ6",
        "outputId": "d9c3eb1e-8839-4e8a-9d57-cde103b42bbc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Colab Notebooks/Candidas/archives/TSC/AllCandidas/AllCandidas\n",
            "/content/drive/MyDrive/Colab Notebooks/Candidas/archives/TSC/AllCandidas/AllCandidas_TRAIN.csv\n",
            "/content/drive/MyDrive/Colab Notebooks/Candidas/archives/TSC/AllCandidas/AllCandidas_TEST.csv\n",
            "/content/drive/MyDrive/Colab Notebooks/Candidas/archives/TSC/AllCandidas/AllCandidas_VAL.csv\n",
            "Valor do Xtrain no read_all_datasets [[1.993e+04 5.877e+04 1.544e+04 ... 1.188e+03 4.239e+03 4.000e+00]\n",
            " [8.122e+04 7.305e+03 6.886e+03 ... 1.055e+04 7.302e+03 4.000e+00]\n",
            " [8.223e+04 7.305e+03 6.032e+03 ... 1.834e+04 7.841e+03 6.000e+00]\n",
            " ...\n",
            " [2.606e+04 4.686e+04 2.178e+04 ... 2.586e+03 5.592e+03 4.000e+00]\n",
            " [3.245e+04 4.572e+04 2.271e+04 ... 2.613e+03 5.596e+03 5.000e+00]\n",
            " [6.787e+04 1.842e+04 2.108e+04 ... 1.091e+04 6.971e+03 2.000e+00]]\n",
            "Valor do y_train no read_all_datasets [1. 6. 1. 2. 5. 1. 2. 2. 1. 2. 4. 5. 3. 1. 3. 5. 2. 5. 1. 6. 2. 6. 1. 5.\n",
            " 1. 2. 2. 6. 6. 5. 2. 1. 5. 4. 1. 1. 1. 6. 1. 1. 5. 6. 1. 2. 6. 4. 2. 2.\n",
            " 1. 6. 5. 5. 5. 6. 5. 2. 6. 5. 2. 2. 6. 6. 6. 2. 4. 5. 5. 3. 6. 4. 2. 1.\n",
            " 5. 5. 1. 6. 5. 5. 2. 2. 1. 1. 1. 4. 6. 1. 5. 5. 4. 5. 4. 2. 2. 6. 4. 5.\n",
            " 2. 4. 5. 3. 2. 6. 5. 2. 1. 5. 6. 2. 6. 6. 4. 5. 6. 5. 5. 6. 2. 4. 2. 2.\n",
            " 1. 3. 1. 2. 6. 2. 6. 5. 5. 6. 5. 6. 6. 3. 3. 4. 5. 2. 6. 2. 6. 2. 2. 4.\n",
            " 5. 4. 6. 6. 1. 6. 4. 2. 5. 5. 5. 1. 5. 6. 1. 5. 6. 1. 3. 3. 1. 6. 3. 1.\n",
            " 6. 4. 2. 2. 2. 1. 6. 6. 4. 2. 2. 2. 1. 2. 4. 6. 3. 1. 2. 1. 6. 2. 6. 1.\n",
            " 5. 2. 5. 1. 5. 1. 5. 1. 5. 1. 3. 3. 2. 1. 2. 1. 6. 4. 1. 1. 6. 2. 6. 2.\n",
            " 2. 2. 6. 6. 1. 5. 3. 6. 2. 1. 2. 1. 6. 5. 6. 6. 2. 4. 1. 3. 5. 6.]\n",
            "\t\titer 0\n",
            "\t\t\tdataset_name:  AllCandidas\n",
            "valor de x_train no prepare data [[1.993e+04 5.877e+04 1.544e+04 ... 1.188e+03 4.239e+03 4.000e+00]\n",
            " [8.122e+04 7.305e+03 6.886e+03 ... 1.055e+04 7.302e+03 4.000e+00]\n",
            " [8.223e+04 7.305e+03 6.032e+03 ... 1.834e+04 7.841e+03 6.000e+00]\n",
            " ...\n",
            " [2.606e+04 4.686e+04 2.178e+04 ... 2.586e+03 5.592e+03 4.000e+00]\n",
            " [3.245e+04 4.572e+04 2.271e+04 ... 2.613e+03 5.596e+03 5.000e+00]\n",
            " [6.787e+04 1.842e+04 2.108e+04 ... 1.091e+04 6.971e+03 2.000e+00]]\n",
            "valor de y_train no prepare data [1. 6. 1. 2. 5. 1. 2. 2. 1. 2. 4. 5. 3. 1. 3. 5. 2. 5. 1. 6. 2. 6. 1. 5.\n",
            " 1. 2. 2. 6. 6. 5. 2. 1. 5. 4. 1. 1. 1. 6. 1. 1. 5. 6. 1. 2. 6. 4. 2. 2.\n",
            " 1. 6. 5. 5. 5. 6. 5. 2. 6. 5. 2. 2. 6. 6. 6. 2. 4. 5. 5. 3. 6. 4. 2. 1.\n",
            " 5. 5. 1. 6. 5. 5. 2. 2. 1. 1. 1. 4. 6. 1. 5. 5. 4. 5. 4. 2. 2. 6. 4. 5.\n",
            " 2. 4. 5. 3. 2. 6. 5. 2. 1. 5. 6. 2. 6. 6. 4. 5. 6. 5. 5. 6. 2. 4. 2. 2.\n",
            " 1. 3. 1. 2. 6. 2. 6. 5. 5. 6. 5. 6. 6. 3. 3. 4. 5. 2. 6. 2. 6. 2. 2. 4.\n",
            " 5. 4. 6. 6. 1. 6. 4. 2. 5. 5. 5. 1. 5. 6. 1. 5. 6. 1. 3. 3. 1. 6. 3. 1.\n",
            " 6. 4. 2. 2. 2. 1. 6. 6. 4. 2. 2. 2. 1. 2. 4. 6. 3. 1. 2. 1. 6. 2. 6. 1.\n",
            " 5. 2. 5. 1. 5. 1. 5. 1. 5. 1. 3. 3. 2. 1. 2. 1. 6. 4. 1. 1. 6. 2. 6. 2.\n",
            " 2. 2. 6. 6. 1. 5. 3. 6. 2. 1. 2. 1. 6. 5. 6. 6. 2. 4. 1. 3. 5. 6.]\n",
            "valor de y_val no prepare data [6. 3. 2. 2. 2. 2. 6. 2. 5. 1. 2. 3. 2. 2. 1. 2. 5. 2. 2. 2. 1. 1. 1. 2.\n",
            " 5. 1. 6. 3. 2. 6. 2. 4. 1. 6. 6. 1. 6. 3. 6. 6. 6. 4. 6. 5. 1. 4. 2. 5.\n",
            " 2. 5. 3. 6. 2. 6. 3. 2. 3. 3. 3. 6. 5. 4. 1. 5. 2. 6. 6. 1. 6. 6. 2. 6.\n",
            " 4. 6. 1. 3. 5. 6. 2.]\n",
            "Dentro do FitModel\n",
            "2/2 [==============================] - 1s 147ms/step\n",
            "y_pred before save =  \n",
            " [[2.10030635e-06 9.99893069e-01 4.61774243e-06 7.73048087e-05\n",
            "  5.49200604e-06 1.73951485e-05]\n",
            " [6.55750000e-06 9.99622464e-01 1.80526640e-05 3.05004418e-04\n",
            "  1.75772202e-05 3.02684984e-05]\n",
            " [2.57994856e-07 1.95824341e-05 9.99908447e-01 3.43649335e-05\n",
            "  3.69655390e-05 4.36214805e-07]\n",
            " [2.88073011e-06 1.56685255e-05 2.42494953e-05 9.99948025e-01\n",
            "  9.11035659e-06 5.90037601e-08]\n",
            " [3.96328833e-05 1.13716735e-04 2.85033238e-05 3.01724936e-06\n",
            "  2.72686029e-05 9.99787867e-01]\n",
            " [2.99844414e-05 4.73687469e-05 5.65668324e-06 8.52444657e-07\n",
            "  8.58661195e-04 9.99057472e-01]\n",
            " [2.69178804e-06 9.99894261e-01 2.85428246e-06 8.87454444e-05\n",
            "  9.47334229e-06 1.98602902e-06]\n",
            " [4.66272031e-05 1.92062769e-04 6.40114231e-05 4.87765919e-06\n",
            "  3.24904940e-05 9.99659896e-01]\n",
            " [9.99445856e-01 7.86238525e-05 7.25217797e-06 1.80269035e-05\n",
            "  3.14573408e-04 1.35708164e-04]\n",
            " [2.32259640e-06 9.99841928e-01 1.42776275e-06 1.95093594e-06\n",
            "  2.15096261e-05 1.30950066e-04]\n",
            " [4.02116439e-06 1.33884105e-05 4.25018443e-05 9.99923468e-01\n",
            "  1.65417860e-05 6.46067377e-08]\n",
            " [1.63372024e-05 9.99830604e-01 5.62043533e-06 4.44204707e-05\n",
            "  8.37818297e-05 1.91878480e-05]\n",
            " [9.99974728e-01 1.41377141e-05 4.37236386e-10 9.56785334e-06\n",
            "  1.48711717e-06 8.93144545e-08]\n",
            " [7.40572228e-04 1.93971373e-05 7.68131031e-06 4.83810527e-06\n",
            "  9.99226451e-01 1.12099337e-06]\n",
            " [2.21362825e-06 9.99902964e-01 3.39221879e-06 6.94320697e-05\n",
            "  5.13955138e-06 1.68015522e-05]\n",
            " [1.91436894e-03 9.97296512e-01 1.78628454e-07 7.94479183e-06\n",
            "  2.16510278e-04 5.64613671e-04]\n",
            " [1.10028768e-05 1.06185907e-04 6.36049936e-06 9.99874949e-01\n",
            "  1.32709204e-06 2.70342980e-07]\n",
            " [2.28595687e-03 4.98438487e-04 1.84713812e-07 1.88618685e-07\n",
            "  5.54742314e-07 9.97214615e-01]\n",
            " [2.00528611e-05 9.99942780e-01 1.12713472e-07 4.95559379e-06\n",
            "  4.68241251e-06 2.73411879e-05]\n",
            " [9.99929786e-01 1.74745346e-05 9.66877334e-09 1.74793677e-05\n",
            "  3.47828645e-05 4.29388564e-07]\n",
            " [6.53088573e-05 1.03478887e-05 1.95212560e-04 1.72452728e-05\n",
            "  9.99711335e-01 4.73775970e-07]\n",
            " [4.40867479e-05 9.58283272e-06 4.81995521e-05 5.73727948e-06\n",
            "  9.99892116e-01 2.90967677e-07]\n",
            " [2.67460905e-06 1.80617826e-05 2.04439566e-05 9.99951959e-01\n",
            "  6.68404618e-06 6.37564384e-08]\n",
            " [1.05583067e-05 7.93537112e-08 1.36193273e-06 1.23268734e-07\n",
            "  9.99818265e-01 1.69655061e-04]\n",
            " [1.01473146e-04 1.02390759e-05 6.43415042e-05 2.71127574e-05\n",
            "  9.99796450e-01 3.15099214e-07]\n",
            " [9.99986291e-01 1.24850118e-07 1.03876881e-11 1.23144574e-07\n",
            "  1.34265383e-05 2.83837265e-09]\n",
            " [1.39206825e-02 5.04334312e-05 7.45749446e-07 3.36163822e-07\n",
            "  6.93164679e-07 9.86027122e-01]\n",
            " [9.99814093e-01 5.93907607e-05 8.81489814e-09 1.21211582e-04\n",
            "  4.79529581e-06 5.49638912e-07]\n",
            " [8.91800664e-05 1.68729472e-04 8.51419145e-07 3.40143885e-07\n",
            "  6.80430239e-05 9.99672890e-01]\n",
            " [4.05892148e-04 1.41586133e-04 4.39677109e-07 2.10982918e-07\n",
            "  1.23028528e-07 9.99451697e-01]\n",
            " [2.87037039e-07 2.01245278e-08 1.19111940e-06 7.44460920e-08\n",
            "  9.99916434e-01 8.20608839e-05]\n",
            " [2.79211119e-04 1.63650664e-04 9.68351014e-06 7.50787694e-06\n",
            "  5.01395880e-05 9.99489784e-01]\n",
            " [1.40862743e-04 2.37144122e-05 2.84777107e-05 3.20453387e-06\n",
            "  9.99803364e-01 3.52501871e-07]\n",
            " [2.41556245e-05 9.98685300e-01 3.38143036e-05 1.18641939e-03\n",
            "  5.25471187e-05 1.77071815e-05]\n",
            " [4.89349070e-04 1.96231646e-04 3.23170934e-05 1.19035421e-05\n",
            "  2.02313633e-04 9.99067843e-01]\n",
            " [7.71156338e-05 1.20625800e-05 1.84692355e-04 2.23528587e-05\n",
            "  9.99703228e-01 4.82300266e-07]\n",
            " [1.10581721e-04 1.04973251e-05 2.79283649e-05 4.53206030e-06\n",
            "  9.99846220e-01 2.81707202e-07]\n",
            " [3.18459584e-04 6.68014691e-05 2.66495732e-07 1.46690056e-07\n",
            "  8.77141773e-08 9.99614120e-01]\n",
            " [7.59739180e-07 6.65519246e-06 9.99820173e-01 6.42866653e-05\n",
            "  1.07625616e-04 5.47225852e-07]\n",
            " [2.53508034e-07 2.68394742e-05 9.99894857e-01 4.36497685e-05\n",
            "  3.39612561e-05 4.86850809e-07]\n",
            " [5.94571054e-01 2.36939825e-03 1.87453770e-06 1.13742658e-06\n",
            "  1.58777493e-05 4.03040737e-01]\n",
            " [3.26174370e-04 6.16704347e-05 3.26510635e-05 1.39928488e-05\n",
            "  9.99564826e-01 6.97487224e-07]\n",
            " [2.34190720e-05 9.99972105e-01 3.58432883e-09 5.88771627e-07\n",
            "  1.78126788e-06 2.13739713e-06]\n",
            " [2.20551374e-05 1.10659581e-04 3.94229028e-06 2.72263696e-06\n",
            "  9.99826252e-01 3.44014552e-05]\n",
            " [1.18361877e-05 9.99002039e-01 4.89481090e-06 6.17130854e-06\n",
            "  5.09099955e-05 9.24254942e-04]\n",
            " [9.99981642e-01 1.75917444e-06 7.78307054e-08 1.44847820e-06\n",
            "  3.68229780e-06 1.13814567e-05]\n",
            " [1.82408548e-05 1.24723698e-07 1.36552103e-06 1.23096754e-07\n",
            "  9.99763906e-01 2.16182234e-04]\n",
            " [9.99969959e-01 1.31525368e-07 3.62748998e-10 2.24415864e-08\n",
            "  1.71474923e-08 2.99416733e-05]\n",
            " [3.08109452e-06 9.99975204e-01 8.18408665e-08 3.55748989e-06\n",
            "  1.14892316e-06 1.68545230e-05]\n",
            " [3.99394457e-06 9.99610603e-01 9.96739327e-05 1.82099975e-04\n",
            "  9.87623644e-05 4.76892956e-06]\n",
            " [9.66430247e-01 3.34170163e-02 8.13343881e-09 1.52613458e-04\n",
            "  5.73161500e-08 7.57237939e-10]\n",
            " [3.15417765e-07 1.06206287e-04 9.99799907e-01 2.60435791e-05\n",
            "  6.66054111e-05 8.64931906e-07]\n",
            " [1.92782038e-03 9.98069227e-01 2.83083121e-08 2.67315249e-06\n",
            "  2.49850615e-07 7.42643236e-09]\n",
            " [2.56031752e-04 2.04681855e-04 2.87405828e-06 1.36915241e-06\n",
            "  1.23383047e-03 9.98301208e-01]\n",
            " [9.99945402e-01 1.11110221e-05 6.26684926e-09 1.33043168e-05\n",
            "  2.98212235e-05 2.80462046e-07]\n",
            " [7.11482744e-06 9.99938130e-01 4.18733066e-07 1.60490545e-05\n",
            "  3.68563678e-06 3.45874614e-05]\n",
            " [3.22820779e-05 1.63828445e-04 5.56730674e-06 1.17259788e-06\n",
            "  4.15568298e-04 9.99381542e-01]\n",
            " [1.36601133e-02 3.57680343e-04 1.48638674e-06 4.09528525e-07\n",
            "  1.03521825e-05 9.85969961e-01]\n",
            " [9.99634862e-01 3.64993408e-04 1.36854304e-11 5.82736241e-08\n",
            "  1.17418274e-07 4.52549216e-08]\n",
            " [1.02060287e-04 1.16252058e-05 6.83868566e-05 3.09629067e-05\n",
            "  9.99786675e-01 3.31176636e-07]\n",
            " [6.47989582e-05 5.55251063e-07 6.51955645e-08 9.45899270e-09\n",
            "  9.06441429e-08 9.99934435e-01]\n",
            " [8.38415726e-05 1.31813476e-05 9.31627728e-05 1.73458320e-05\n",
            "  9.99792039e-01 4.26172022e-07]\n",
            " [8.50155411e-05 1.26361192e-05 2.40621011e-04 2.59554399e-05\n",
            "  9.99635220e-01 6.25520443e-07]\n",
            " [9.99941468e-01 7.03757905e-07 5.82118043e-09 9.87043222e-06\n",
            "  5.28088606e-07 4.74391127e-05]\n",
            " [8.33198574e-05 1.38077794e-05 3.26344249e-04 2.81461453e-05\n",
            "  9.99547660e-01 7.01464330e-07]\n",
            " [4.54009569e-04 1.76735790e-04 2.82634119e-05 1.05813979e-05\n",
            "  1.74743574e-04 9.99155641e-01]\n",
            " [4.44804616e-02 2.69414624e-04 1.53727410e-06 4.11108203e-07\n",
            "  1.15860903e-05 9.55236614e-01]\n",
            " [6.73224640e-05 8.52212816e-06 8.27225595e-05 2.76192568e-05\n",
            "  9.99813616e-01 2.61946354e-07]\n",
            " [4.81902476e-04 6.61479789e-05 3.95732241e-05 2.92859932e-05\n",
            "  9.99382138e-01 9.59589670e-07]\n",
            " [9.99944568e-01 2.56980929e-05 1.78192627e-09 2.72226462e-05\n",
            "  2.29065358e-06 2.25046833e-07]\n",
            " [5.95428162e-07 1.12546310e-08 1.00166460e-06 7.29496605e-08\n",
            "  9.99958277e-01 4.00786048e-05]\n",
            " [5.08521498e-06 9.99969959e-01 6.11808417e-08 2.59616695e-06\n",
            "  1.45498632e-06 2.08908987e-05]\n",
            " [9.99695778e-01 7.68399514e-06 1.64159388e-07 5.06059951e-05\n",
            "  1.05595849e-04 1.40315722e-04]\n",
            " [9.99495745e-01 5.03831659e-04 7.84436925e-12 7.15015034e-08\n",
            "  2.23442754e-07 1.83479454e-08]\n",
            " [2.19564354e-05 9.98604476e-01 3.41479972e-05 1.26824284e-03\n",
            "  3.80992060e-05 3.31259544e-05]\n",
            " [2.30388629e-04 3.18258157e-04 1.12629214e-05 7.97739631e-06\n",
            "  4.71753738e-05 9.99384880e-01]\n",
            " [1.44968817e-06 9.99944925e-01 1.44490275e-06 3.67876673e-05\n",
            "  2.88388492e-06 1.25267625e-05]\n",
            " [1.57015838e-05 9.99322653e-01 3.47996433e-06 5.35256731e-06\n",
            "  1.49524221e-05 6.37852645e-04]\n",
            " [9.09871638e-01 6.11100637e-04 2.59121025e-05 6.71363494e-04\n",
            "  8.54382589e-02 3.38165509e-03]\n",
            " [1.95313464e-06 9.68304448e-06 9.99412060e-01 1.13163354e-04\n",
            "  4.62110620e-04 9.86709210e-07]]\n",
            "Histórico\n",
            "          loss  accuracy    recall  precision  true_positives  true_negatives  \\\n",
            "0     1.578485  0.415966  0.210084   0.515464            50.0          1143.0   \n",
            "1     1.079308  0.525210  0.310924   0.643478            74.0          1149.0   \n",
            "2     0.977791  0.609244  0.445378   0.675159           106.0          1139.0   \n",
            "3     0.991046  0.550420  0.399160   0.641892            95.0          1137.0   \n",
            "4     0.852824  0.655462  0.525210   0.762195           125.0          1151.0   \n",
            "...        ...       ...       ...        ...             ...             ...   \n",
            "1495  0.011309  0.995798  0.995798   0.995798           237.0          1189.0   \n",
            "1496  0.013195  0.995798  0.995798   0.995798           237.0          1189.0   \n",
            "1497  0.012314  0.995798  0.995798   0.995798           237.0          1189.0   \n",
            "1498  0.012169  0.991597  0.991597   0.991597           236.0          1188.0   \n",
            "1499  0.013168  0.995798  0.995798   0.995798           237.0          1189.0   \n",
            "\n",
            "      false_positives  false_negatives      lr  \n",
            "0                47.0            188.0  0.0010  \n",
            "1                41.0            164.0  0.0010  \n",
            "2                51.0            132.0  0.0010  \n",
            "3                53.0            143.0  0.0010  \n",
            "4                39.0            113.0  0.0010  \n",
            "...               ...              ...     ...  \n",
            "1495              1.0              1.0  0.0001  \n",
            "1496              1.0              1.0  0.0001  \n",
            "1497              1.0              1.0  0.0001  \n",
            "1498              2.0              2.0  0.0001  \n",
            "1499              1.0              1.0  0.0001  \n",
            "\n",
            "[1500 rows x 9 columns]\n",
            "Temp: 0.9605908152734779\n",
            "   precision  accuracy    recall  f1_score    duration  std  specificity\n",
            "0   0.960591      0.95  0.962061  0.961071  589.806381  0.0     0.989455\n",
            "\t\t\t\tDONE\n",
            "\t\titer 1\n",
            "\t\t\tdataset_name:  AllCandidas\n",
            "valor de x_train no prepare data [[1.993e+04 5.877e+04 1.544e+04 ... 1.188e+03 4.239e+03 4.000e+00]\n",
            " [8.122e+04 7.305e+03 6.886e+03 ... 1.055e+04 7.302e+03 4.000e+00]\n",
            " [8.223e+04 7.305e+03 6.032e+03 ... 1.834e+04 7.841e+03 6.000e+00]\n",
            " ...\n",
            " [2.606e+04 4.686e+04 2.178e+04 ... 2.586e+03 5.592e+03 4.000e+00]\n",
            " [3.245e+04 4.572e+04 2.271e+04 ... 2.613e+03 5.596e+03 5.000e+00]\n",
            " [6.787e+04 1.842e+04 2.108e+04 ... 1.091e+04 6.971e+03 2.000e+00]]\n",
            "valor de y_train no prepare data [1. 6. 1. 2. 5. 1. 2. 2. 1. 2. 4. 5. 3. 1. 3. 5. 2. 5. 1. 6. 2. 6. 1. 5.\n",
            " 1. 2. 2. 6. 6. 5. 2. 1. 5. 4. 1. 1. 1. 6. 1. 1. 5. 6. 1. 2. 6. 4. 2. 2.\n",
            " 1. 6. 5. 5. 5. 6. 5. 2. 6. 5. 2. 2. 6. 6. 6. 2. 4. 5. 5. 3. 6. 4. 2. 1.\n",
            " 5. 5. 1. 6. 5. 5. 2. 2. 1. 1. 1. 4. 6. 1. 5. 5. 4. 5. 4. 2. 2. 6. 4. 5.\n",
            " 2. 4. 5. 3. 2. 6. 5. 2. 1. 5. 6. 2. 6. 6. 4. 5. 6. 5. 5. 6. 2. 4. 2. 2.\n",
            " 1. 3. 1. 2. 6. 2. 6. 5. 5. 6. 5. 6. 6. 3. 3. 4. 5. 2. 6. 2. 6. 2. 2. 4.\n",
            " 5. 4. 6. 6. 1. 6. 4. 2. 5. 5. 5. 1. 5. 6. 1. 5. 6. 1. 3. 3. 1. 6. 3. 1.\n",
            " 6. 4. 2. 2. 2. 1. 6. 6. 4. 2. 2. 2. 1. 2. 4. 6. 3. 1. 2. 1. 6. 2. 6. 1.\n",
            " 5. 2. 5. 1. 5. 1. 5. 1. 5. 1. 3. 3. 2. 1. 2. 1. 6. 4. 1. 1. 6. 2. 6. 2.\n",
            " 2. 2. 6. 6. 1. 5. 3. 6. 2. 1. 2. 1. 6. 5. 6. 6. 2. 4. 1. 3. 5. 6.]\n",
            "valor de y_val no prepare data [6. 3. 2. 2. 2. 2. 6. 2. 5. 1. 2. 3. 2. 2. 1. 2. 5. 2. 2. 2. 1. 1. 1. 2.\n",
            " 5. 1. 6. 3. 2. 6. 2. 4. 1. 6. 6. 1. 6. 3. 6. 6. 6. 4. 6. 5. 1. 4. 2. 5.\n",
            " 2. 5. 3. 6. 2. 6. 3. 2. 3. 3. 3. 6. 5. 4. 1. 5. 2. 6. 6. 1. 6. 6. 2. 6.\n",
            " 4. 6. 1. 3. 5. 6. 2.]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-15-c033a5082e59>:21: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  df_best_model = pd.DataFrame(data=np.zeros((1, 6), dtype=np.float), index=[0],\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dentro do FitModel\n",
            "2/2 [==============================] - 1s 30ms/step\n",
            "y_pred before save =  \n",
            " [[8.21470735e-07 9.99926925e-01 3.19230116e-06 4.85431083e-05\n",
            "  4.00499312e-06 1.64947887e-05]\n",
            " [3.08247513e-06 9.99696493e-01 1.04843084e-05 2.43640709e-04\n",
            "  1.10821511e-05 3.53343676e-05]\n",
            " [2.21175682e-07 1.41997261e-05 9.99969363e-01 9.83273185e-06\n",
            "  4.48564288e-06 1.90254593e-06]\n",
            " [1.31589450e-05 2.75345137e-05 6.35775214e-05 9.99887705e-01\n",
            "  6.21140680e-06 1.92610810e-06]\n",
            " [5.53234759e-06 6.58837525e-05 3.01612799e-05 2.50658081e-06\n",
            "  2.17033339e-05 9.99874234e-01]\n",
            " [1.28879110e-05 2.54523984e-05 5.74117678e-07 1.10376652e-06\n",
            "  6.83113904e-05 9.99891639e-01]\n",
            " [1.31168053e-06 9.99913692e-01 2.18213199e-06 6.62502207e-05\n",
            "  1.18280586e-05 4.73000728e-06]\n",
            " [5.54030385e-06 8.18030749e-05 4.37379131e-05 2.69464908e-06\n",
            "  2.16676381e-05 9.99844551e-01]\n",
            " [9.99825060e-01 1.86255293e-05 1.28438643e-07 1.29565640e-04\n",
            "  2.07224530e-05 5.93202867e-06]\n",
            " [1.52154414e-07 9.99977112e-01 2.93121150e-09 3.46849987e-07\n",
            "  1.02567060e-06 2.13558924e-05]\n",
            " [1.20849882e-05 1.78222563e-05 1.55416536e-04 9.99806345e-01\n",
            "  6.30047816e-06 2.06527284e-06]\n",
            " [8.82249060e-06 9.99956250e-01 1.92792782e-09 3.60895297e-06\n",
            "  1.47883256e-05 1.65059409e-05]\n",
            " [9.99918699e-01 4.59040311e-05 8.60948468e-09 2.77774889e-05\n",
            "  6.07675929e-06 1.49254072e-06]\n",
            " [2.44994502e-04 1.98677626e-05 8.31110538e-06 3.32678451e-06\n",
            "  9.99704421e-01 1.90864066e-05]\n",
            " [1.03310481e-06 9.99921679e-01 2.46463810e-06 5.25733049e-05\n",
            "  4.43320550e-06 1.77140282e-05]\n",
            " [1.64504088e-02 9.81399000e-01 3.89779720e-09 1.49999296e-05\n",
            "  1.61216478e-04 1.97431818e-03]\n",
            " [4.48261235e-05 3.57214332e-04 9.12165160e-06 9.99579251e-01\n",
            "  4.07216294e-06 5.46710908e-06]\n",
            " [3.30383256e-02 2.30797636e-03 5.00090671e-08 4.59459443e-06\n",
            "  7.79241873e-06 9.64641213e-01]\n",
            " [1.57489540e-05 9.99930501e-01 5.62114124e-08 6.57181181e-06\n",
            "  5.33696766e-06 4.17155934e-05]\n",
            " [9.99584138e-01 1.32691363e-04 1.94093900e-07 1.15044728e-04\n",
            "  1.58143521e-04 9.75642615e-06]\n",
            " [9.16440695e-05 2.11515544e-05 3.01806722e-04 3.55032898e-05\n",
            "  9.99543846e-01 6.12963140e-06]\n",
            " [1.00011115e-04 4.17277879e-05 3.78775985e-05 1.34458105e-05\n",
            "  9.99803245e-01 3.75163472e-06]\n",
            " [1.26625109e-05 2.84671023e-05 4.05111059e-05 9.99911427e-01\n",
            "  5.10722475e-06 1.83382383e-06]\n",
            " [7.21303832e-06 5.25019956e-08 5.97807954e-08 3.77771443e-07\n",
            "  9.99472082e-01 5.20219386e-04]\n",
            " [7.52481574e-05 5.25654877e-06 3.57140343e-05 1.03084240e-05\n",
            "  9.99871731e-01 1.61488481e-06]\n",
            " [9.99728978e-01 2.02748153e-04 5.70173353e-11 2.67404835e-06\n",
            "  6.54239702e-05 2.79890997e-07]\n",
            " [2.84697395e-02 1.56729759e-04 4.65233740e-07 1.80019310e-06\n",
            "  1.62259005e-06 9.71369624e-01]\n",
            " [9.99660969e-01 1.06674685e-04 6.26336103e-08 2.11931154e-04\n",
            "  1.71309275e-05 3.23505765e-06]\n",
            " [1.78661357e-05 4.93810549e-05 3.97373903e-08 6.29833892e-07\n",
            "  2.29010402e-06 9.99929786e-01]\n",
            " [1.83876033e-03 3.74311116e-03 6.00830447e-07 7.81197014e-06\n",
            "  9.24975211e-06 9.94400442e-01]\n",
            " [1.60027025e-06 2.45149721e-07 7.72847031e-08 3.02467583e-07\n",
            "  9.97467160e-01 2.53054942e-03]\n",
            " [8.42822701e-05 2.81738430e-05 3.85307658e-06 4.89587546e-06\n",
            "  4.65705943e-06 9.99874115e-01]\n",
            " [6.22492807e-05 2.55231389e-05 2.72420948e-05 3.53069345e-06\n",
            "  9.99873877e-01 7.54577650e-06]\n",
            " [9.29828275e-06 9.99082088e-01 1.50834794e-05 8.31269135e-04\n",
            "  3.47667046e-05 2.75570728e-05]\n",
            " [3.88911067e-05 1.09947046e-04 2.00770137e-05 3.35657228e-06\n",
            "  1.25020524e-04 9.99702632e-01]\n",
            " [1.13343092e-04 2.29970683e-05 2.58199405e-04 4.34935209e-05\n",
            "  9.99556124e-01 5.86082751e-06]\n",
            " [5.58685351e-05 9.82976871e-06 2.37204313e-05 3.37724987e-06\n",
            "  9.99903560e-01 3.63502750e-06]\n",
            " [1.24387571e-03 1.41117978e-03 3.13339854e-07 4.52403128e-06\n",
            "  3.62137257e-06 9.97336566e-01]\n",
            " [5.03770423e-07 4.46550212e-06 9.99961019e-01 1.90923802e-05\n",
            "  1.31726547e-05 1.78670587e-06]\n",
            " [2.29409935e-07 1.84858400e-05 9.99962449e-01 1.24426606e-05\n",
            "  4.24803420e-06 2.21744085e-06]\n",
            " [9.00577188e-01 1.83836193e-04 3.72537627e-08 6.65072491e-07\n",
            "  1.28884142e-06 9.92369950e-02]\n",
            " [1.82351301e-04 4.06467334e-05 3.28178648e-05 9.45921056e-06\n",
            "  9.99727070e-01 7.61823640e-06]\n",
            " [1.32947735e-05 9.99983191e-01 5.92994542e-10 1.39050215e-07\n",
            "  4.05986754e-07 2.88931369e-06]\n",
            " [3.76762509e-05 1.69020321e-04 4.83546410e-06 1.79739231e-06\n",
            "  9.99581397e-01 2.05299395e-04]\n",
            " [1.12277678e-06 9.99803007e-01 2.17239933e-08 1.37449967e-06\n",
            "  4.34575031e-06 1.90134626e-04]\n",
            " [9.99980927e-01 8.41521512e-07 1.47062573e-09 1.58946623e-05\n",
            "  1.88969659e-06 5.27893917e-07]\n",
            " [1.03582397e-05 6.63035422e-08 6.07361841e-08 4.68581277e-07\n",
            "  9.99420047e-01 5.69034542e-04]\n",
            " [1.00000000e+00 6.74203332e-11 4.11183500e-12 8.14439005e-09\n",
            "  4.61441441e-10 9.75702630e-09]\n",
            " [2.46739774e-06 9.99949694e-01 9.04669264e-08 4.25813641e-06\n",
            "  2.75364687e-06 4.07547341e-05]\n",
            " [1.55011287e-06 9.99751270e-01 1.10066423e-04 6.58966383e-05\n",
            "  5.76522907e-05 1.35846713e-05]\n",
            " [1.03628452e-06 9.99691248e-01 1.81552169e-11 1.10423737e-09\n",
            "  3.07739509e-04 1.53475579e-08]\n",
            " [3.76712762e-07 1.86441088e-04 9.99787867e-01 6.27848021e-06\n",
            "  1.38517626e-05 5.24941015e-06]\n",
            " [1.75294879e-09 9.99999881e-01 2.60458015e-15 1.55790832e-11\n",
            "  1.33881699e-07 2.74382036e-12]\n",
            " [4.92950348e-05 1.00580228e-05 2.58534044e-07 1.98460339e-06\n",
            "  1.58548108e-04 9.99779880e-01]\n",
            " [9.99600828e-01 1.12973568e-04 1.81976233e-07 1.01233323e-04\n",
            "  1.75067034e-04 9.70277142e-06]\n",
            " [5.43701753e-06 9.99892473e-01 3.95307637e-07 1.58640451e-05\n",
            "  7.15892611e-06 7.87173776e-05]\n",
            " [1.87057121e-05 1.69679246e-04 1.06308812e-06 2.96767212e-06\n",
            "  7.17957591e-05 9.99735773e-01]\n",
            " [8.58286992e-02 1.33397945e-04 3.15041966e-08 6.15005206e-07\n",
            "  1.10481233e-06 9.14036155e-01]\n",
            " [9.69103456e-01 3.08457632e-02 2.21470238e-11 8.80959760e-06\n",
            "  2.32387920e-05 1.87629503e-05]\n",
            " [7.91671337e-05 5.82495295e-06 3.69816298e-05 1.14337045e-05\n",
            "  9.99864936e-01 1.67449514e-06]\n",
            " [4.53826976e-09 4.68461173e-11 4.16940232e-11 6.29681333e-12\n",
            "  2.58653585e-11 1.00000000e+00]\n",
            " [1.31548499e-04 2.69346456e-05 9.25029017e-05 3.10539908e-05\n",
            "  9.99713361e-01 4.54355677e-06]\n",
            " [9.71578484e-05 1.96766978e-05 3.49499489e-04 4.20522410e-05\n",
            "  9.99485373e-01 6.16168882e-06]\n",
            " [9.99820292e-01 1.11267184e-06 4.77021786e-07 1.90077972e-05\n",
            "  1.47738604e-06 1.57705639e-04]\n",
            " [1.01674712e-04 2.22282997e-05 5.23652241e-04 4.89117992e-05\n",
            "  9.99295831e-01 7.59003797e-06]\n",
            " [3.81287282e-05 9.47766384e-05 1.90670835e-05 3.06311449e-06\n",
            "  1.05376748e-04 9.99739587e-01]\n",
            " [3.76552254e-01 1.70726940e-04 4.22575717e-08 8.57801865e-07\n",
            "  1.74361901e-06 6.23274446e-01]\n",
            " [5.99750165e-05 5.34621813e-06 4.69501138e-05 1.09507891e-05\n",
            "  9.99875069e-01 1.64359062e-06]\n",
            " [2.52182595e-04 4.11054607e-05 3.62491919e-05 1.67927919e-05\n",
            "  9.99646664e-01 7.02752823e-06]\n",
            " [9.99871135e-01 5.57446874e-05 2.00969588e-08 6.23259111e-05\n",
            "  8.84172641e-06 1.83084580e-06]\n",
            " [8.73334784e-07 2.68483227e-08 2.03396375e-08 1.00841362e-07\n",
            "  9.99754965e-01 2.43936985e-04]\n",
            " [4.30018918e-06 9.99947548e-01 5.22767039e-08 3.97081340e-06\n",
            "  3.01143814e-06 4.10887478e-05]\n",
            " [9.97420430e-01 2.29207872e-05 8.56472525e-06 1.61303018e-04\n",
            "  2.08090199e-03 3.05851048e-04]\n",
            " [9.96266067e-01 3.72467772e-03 3.80225062e-12 4.64264485e-06\n",
            "  3.04290370e-06 1.54129657e-06]\n",
            " [1.27852163e-05 9.98588026e-01 1.67584913e-05 1.30135508e-03\n",
            "  2.66064562e-05 5.45069088e-05]\n",
            " [8.41591391e-05 4.31259832e-05 2.90566572e-06 5.02941566e-06\n",
            "  5.04021409e-06 9.99859810e-01]\n",
            " [7.17533510e-07 9.99953747e-01 1.16213323e-06 2.81864595e-05\n",
            "  3.04980131e-06 1.31461666e-05]\n",
            " [1.40413738e-06 9.99868512e-01 2.78007395e-09 4.98810437e-07\n",
            "  1.20203694e-07 1.29461710e-04]\n",
            " [1.84565827e-01 4.00956254e-04 7.66105877e-05 3.24966939e-04\n",
            "  8.13077092e-01 1.55460497e-03]\n",
            " [1.12308874e-06 6.24037875e-06 9.99917746e-01 3.14907302e-05\n",
            "  4.07537082e-05 2.61286391e-06]]\n",
            "Histórico\n",
            "          loss  accuracy    recall  precision  true_positives  true_negatives  \\\n",
            "0     1.692684  0.323529  0.155462   0.569231            37.0          1162.0   \n",
            "1     1.188783  0.521008  0.336134   0.634921            80.0          1144.0   \n",
            "2     1.054283  0.609244  0.407563   0.687943            97.0          1146.0   \n",
            "3     0.899667  0.651260  0.411765   0.748092            98.0          1157.0   \n",
            "4     0.864937  0.638655  0.487395   0.794521           116.0          1160.0   \n",
            "...        ...       ...       ...        ...             ...             ...   \n",
            "1495  0.021448  0.983193  0.983193   0.983193           234.0          1186.0   \n",
            "1496  0.019846  0.991597  0.991597   0.991597           236.0          1188.0   \n",
            "1497  0.009889  0.995798  0.995798   0.995798           237.0          1189.0   \n",
            "1498  0.021667  0.991597  0.991597   0.991597           236.0          1188.0   \n",
            "1499  0.024606  0.991597  0.991597   0.991597           236.0          1188.0   \n",
            "\n",
            "      false_positives  false_negatives      lr  \n",
            "0                28.0            201.0  0.0010  \n",
            "1                46.0            158.0  0.0010  \n",
            "2                44.0            141.0  0.0010  \n",
            "3                33.0            140.0  0.0010  \n",
            "4                30.0            122.0  0.0010  \n",
            "...               ...              ...     ...  \n",
            "1495              4.0              4.0  0.0001  \n",
            "1496              2.0              2.0  0.0001  \n",
            "1497              1.0              1.0  0.0001  \n",
            "1498              2.0              2.0  0.0001  \n",
            "1499              2.0              2.0  0.0001  \n",
            "\n",
            "[1500 rows x 9 columns]\n",
            "Temp: 0.9818627450980393\n",
            "   precision  accuracy    recall  f1_score    duration  std  specificity\n",
            "0   0.981863     0.975  0.979167  0.979565  570.299246  0.0     0.994664\n",
            "\t\t\t\tDONE\n",
            "\t\titer 2\n",
            "\t\t\tdataset_name:  AllCandidas\n",
            "valor de x_train no prepare data [[1.993e+04 5.877e+04 1.544e+04 ... 1.188e+03 4.239e+03 4.000e+00]\n",
            " [8.122e+04 7.305e+03 6.886e+03 ... 1.055e+04 7.302e+03 4.000e+00]\n",
            " [8.223e+04 7.305e+03 6.032e+03 ... 1.834e+04 7.841e+03 6.000e+00]\n",
            " ...\n",
            " [2.606e+04 4.686e+04 2.178e+04 ... 2.586e+03 5.592e+03 4.000e+00]\n",
            " [3.245e+04 4.572e+04 2.271e+04 ... 2.613e+03 5.596e+03 5.000e+00]\n",
            " [6.787e+04 1.842e+04 2.108e+04 ... 1.091e+04 6.971e+03 2.000e+00]]\n",
            "valor de y_train no prepare data [1. 6. 1. 2. 5. 1. 2. 2. 1. 2. 4. 5. 3. 1. 3. 5. 2. 5. 1. 6. 2. 6. 1. 5.\n",
            " 1. 2. 2. 6. 6. 5. 2. 1. 5. 4. 1. 1. 1. 6. 1. 1. 5. 6. 1. 2. 6. 4. 2. 2.\n",
            " 1. 6. 5. 5. 5. 6. 5. 2. 6. 5. 2. 2. 6. 6. 6. 2. 4. 5. 5. 3. 6. 4. 2. 1.\n",
            " 5. 5. 1. 6. 5. 5. 2. 2. 1. 1. 1. 4. 6. 1. 5. 5. 4. 5. 4. 2. 2. 6. 4. 5.\n",
            " 2. 4. 5. 3. 2. 6. 5. 2. 1. 5. 6. 2. 6. 6. 4. 5. 6. 5. 5. 6. 2. 4. 2. 2.\n",
            " 1. 3. 1. 2. 6. 2. 6. 5. 5. 6. 5. 6. 6. 3. 3. 4. 5. 2. 6. 2. 6. 2. 2. 4.\n",
            " 5. 4. 6. 6. 1. 6. 4. 2. 5. 5. 5. 1. 5. 6. 1. 5. 6. 1. 3. 3. 1. 6. 3. 1.\n",
            " 6. 4. 2. 2. 2. 1. 6. 6. 4. 2. 2. 2. 1. 2. 4. 6. 3. 1. 2. 1. 6. 2. 6. 1.\n",
            " 5. 2. 5. 1. 5. 1. 5. 1. 5. 1. 3. 3. 2. 1. 2. 1. 6. 4. 1. 1. 6. 2. 6. 2.\n",
            " 2. 2. 6. 6. 1. 5. 3. 6. 2. 1. 2. 1. 6. 5. 6. 6. 2. 4. 1. 3. 5. 6.]\n",
            "valor de y_val no prepare data [6. 3. 2. 2. 2. 2. 6. 2. 5. 1. 2. 3. 2. 2. 1. 2. 5. 2. 2. 2. 1. 1. 1. 2.\n",
            " 5. 1. 6. 3. 2. 6. 2. 4. 1. 6. 6. 1. 6. 3. 6. 6. 6. 4. 6. 5. 1. 4. 2. 5.\n",
            " 2. 5. 3. 6. 2. 6. 3. 2. 3. 3. 3. 6. 5. 4. 1. 5. 2. 6. 6. 1. 6. 6. 2. 6.\n",
            " 4. 6. 1. 3. 5. 6. 2.]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-15-c033a5082e59>:21: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  df_best_model = pd.DataFrame(data=np.zeros((1, 6), dtype=np.float), index=[0],\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dentro do FitModel\n",
            "2/2 [==============================] - 1s 31ms/step\n",
            "y_pred before save =  \n",
            " [[1.66298719e-06 9.99962926e-01 1.22174679e-05 2.01963248e-05\n",
            "  1.03512184e-06 1.97785425e-06]\n",
            " [7.19210129e-06 9.99735057e-01 5.30862089e-05 1.92015839e-04\n",
            "  5.36221205e-06 7.32440458e-06]\n",
            " [2.30934205e-07 1.64063749e-05 9.99952078e-01 1.65533074e-05\n",
            "  1.43373654e-05 2.97985650e-07]\n",
            " [4.65400859e-07 4.90181901e-06 2.53971234e-06 9.99978423e-01\n",
            "  1.35540804e-05 1.09937673e-07]\n",
            " [6.89614990e-06 9.52934715e-06 5.97003091e-05 2.98133932e-06\n",
            "  4.00436002e-05 9.99880791e-01]\n",
            " [1.10036390e-05 1.98840899e-05 8.32896603e-07 1.03186972e-06\n",
            "  4.01848192e-05 9.99927044e-01]\n",
            " [1.72791169e-06 9.99964356e-01 6.17962769e-06 1.98258676e-05\n",
            "  7.71216855e-06 2.95127734e-07]\n",
            " [8.99068436e-06 1.40596730e-05 1.11154099e-04 4.21939058e-06\n",
            "  4.25642538e-05 9.99819100e-01]\n",
            " [9.99598086e-01 3.01571912e-04 2.83915347e-06 3.37769279e-06\n",
            "  5.36738917e-05 4.04747771e-05]\n",
            " [5.02530838e-07 9.99962687e-01 6.06239894e-08 8.67067840e-08\n",
            "  1.74367196e-05 1.93273445e-05]\n",
            " [4.26113644e-07 4.52509630e-06 6.72422675e-06 9.99975443e-01\n",
            "  1.26830091e-05 2.04497582e-07]\n",
            " [3.02736535e-05 9.99877691e-01 1.94663542e-07 8.07907441e-07\n",
            "  3.58535508e-05 5.51918965e-05]\n",
            " [9.99380469e-01 3.91289650e-04 5.59620094e-06 9.87787134e-05\n",
            "  8.56491461e-05 3.82490362e-05]\n",
            " [1.97174362e-04 2.47417256e-06 2.67723353e-05 4.53904977e-06\n",
            "  9.99739230e-01 2.98389969e-05]\n",
            " [1.79442839e-06 9.99966025e-01 1.00217367e-05 1.90889787e-05\n",
            "  1.03054288e-06 2.11431689e-06]\n",
            " [9.86447412e-05 9.99735892e-01 5.69755265e-08 8.82689832e-08\n",
            "  4.25582766e-05 1.22712343e-04]\n",
            " [5.03588853e-06 2.12911080e-04 5.88235889e-06 9.99768913e-01\n",
            "  6.49314552e-06 7.84792519e-07]\n",
            " [3.01669294e-04 1.90256425e-04 7.89996975e-08 7.37741530e-08\n",
            "  7.92624348e-07 9.99507070e-01]\n",
            " [4.53757457e-05 9.99903917e-01 4.23695928e-06 1.14719423e-05\n",
            "  2.18987429e-06 3.27532871e-05]\n",
            " [9.98786747e-01 3.88106448e-04 2.55782161e-05 1.50518725e-04\n",
            "  5.06422832e-04 1.42540739e-04]\n",
            " [1.13224720e-04 2.72205034e-06 1.32423229e-04 2.74599224e-05\n",
            "  9.99719441e-01 4.73973023e-06]\n",
            " [1.59117611e-04 2.94640759e-05 6.05746100e-05 2.19186168e-05\n",
            "  9.99725282e-01 3.61200250e-06]\n",
            " [4.63730288e-07 4.35587981e-06 2.07228049e-06 9.99981642e-01\n",
            "  1.14357044e-05 8.93103049e-08]\n",
            " [2.47177595e-05 1.94521863e-06 5.03759168e-07 2.85297887e-07\n",
            "  9.99819577e-01 1.52985289e-04]\n",
            " [4.19587050e-05 9.24392225e-07 3.64055777e-05 3.56748133e-05\n",
            "  9.99879241e-01 5.72870431e-06]\n",
            " [9.99909878e-01 1.76932717e-05 2.56314205e-08 1.82361862e-06\n",
            "  6.74617331e-05 3.15094826e-06]\n",
            " [5.02472837e-03 6.89677927e-06 2.34422146e-07 9.19243845e-08\n",
            "  5.94113544e-07 9.94967401e-01]\n",
            " [9.98092234e-01 9.52135946e-04 2.73721726e-05 6.14276389e-04\n",
            "  2.26452757e-04 8.75278274e-05]\n",
            " [2.39026599e-06 1.17081372e-05 3.31863902e-07 5.17980368e-07\n",
            "  5.97373582e-06 9.99979138e-01]\n",
            " [1.31647132e-04 1.10155643e-05 5.74047228e-08 3.06846601e-08\n",
            "  4.25618758e-08 9.99857187e-01]\n",
            " [4.75696743e-06 2.93843328e-07 3.37477644e-07 9.32615976e-08\n",
            "  9.99932528e-01 6.19814964e-05]\n",
            " [5.39181383e-05 1.62116739e-05 3.08107542e-06 6.82461348e-07\n",
            "  4.93338166e-06 9.99921203e-01]\n",
            " [5.93510995e-05 1.27233534e-05 5.73169673e-05 6.97659834e-06\n",
            "  9.99855518e-01 8.16264037e-06]\n",
            " [1.67755243e-05 9.99221683e-01 7.83666983e-05 6.46156084e-04\n",
            "  3.09739298e-05 6.06550884e-06]\n",
            " [3.19821193e-05 1.95332268e-05 4.54437504e-05 6.10617099e-06\n",
            "  7.17179282e-05 9.99825180e-01]\n",
            " [1.41383920e-04 2.52303312e-06 1.04647414e-04 3.41196646e-05\n",
            "  9.99713242e-01 4.07277503e-06]\n",
            " [5.01354079e-05 3.06638981e-06 5.49949582e-05 7.06511310e-06\n",
            "  9.99874592e-01 1.00828429e-05]\n",
            " [1.01529688e-04 7.47222430e-06 4.02287128e-08 2.25010162e-08\n",
            "  3.22900462e-08 9.99890924e-01]\n",
            " [7.10705820e-07 1.05776408e-05 9.99896884e-01 5.30734360e-05\n",
            "  3.82917606e-05 4.81037091e-07]\n",
            " [2.09050469e-07 1.90778792e-05 9.99949932e-01 1.74988672e-05\n",
            "  1.28831944e-05 2.94276987e-07]\n",
            " [5.72548687e-01 2.93650199e-03 2.04012531e-06 7.98259748e-07\n",
            "  4.71555722e-05 4.24464792e-01]\n",
            " [2.03531061e-04 2.32002712e-05 9.39267920e-05 2.34194140e-05\n",
            "  9.99634862e-01 2.10756334e-05]\n",
            " [2.70821374e-06 9.99996424e-01 6.41707913e-08 8.68273702e-08\n",
            "  1.03567146e-07 6.01241538e-07]\n",
            " [2.03742729e-06 1.10725323e-05 5.69741223e-06 6.50741526e-07\n",
            "  9.99965787e-01 1.47450492e-05]\n",
            " [2.65763765e-06 9.99729931e-01 3.64363956e-07 4.98867848e-07\n",
            "  5.61234701e-05 2.10507278e-04]\n",
            " [9.99981523e-01 4.70037003e-06 7.55309770e-08 2.45432261e-07\n",
            "  4.45026762e-06 8.99012139e-06]\n",
            " [3.08919771e-05 3.85786961e-06 5.66958477e-07 3.35700378e-07\n",
            "  9.99767840e-01 1.96525187e-04]\n",
            " [9.99925852e-01 1.13342412e-06 9.66894333e-08 1.51030278e-07\n",
            "  3.64971174e-06 6.90393354e-05]\n",
            " [9.31684826e-06 9.99960542e-01 4.12642839e-06 8.55014241e-06\n",
            "  4.54699773e-07 1.70694802e-05]\n",
            " [2.36612300e-06 9.99725521e-01 1.73043722e-04 1.99864426e-05\n",
            "  7.84676959e-05 5.77814717e-07]\n",
            " [7.22995042e-09 9.99999642e-01 4.84527800e-11 8.45047502e-13\n",
            "  3.12477169e-07 7.33856471e-14]\n",
            " [2.51354692e-07 9.52029368e-05 9.99876738e-01 7.26407643e-06\n",
            "  2.01204020e-05 4.36114846e-07]\n",
            " [6.29154895e-10 1.00000000e+00 4.32955456e-13 4.56558958e-14\n",
            "  1.29066446e-08 1.50689601e-14]\n",
            " [1.34738948e-05 1.29921909e-05 1.45216393e-06 1.50956521e-06\n",
            "  1.06409090e-04 9.99864101e-01]\n",
            " [9.98918295e-01 3.20192310e-04 2.06998520e-05 1.27192063e-04\n",
            "  4.81861207e-04 1.31704262e-04]\n",
            " [2.14092433e-05 9.99887705e-01 1.36029375e-05 3.78322002e-05\n",
            "  1.80012728e-06 3.74994306e-05]\n",
            " [1.71070678e-05 8.23001319e-05 1.13077670e-06 1.61342018e-06\n",
            "  4.83573058e-05 9.99849439e-01]\n",
            " [4.94837062e-03 4.37631272e-04 1.43529732e-07 5.36210791e-08\n",
            "  1.08648567e-06 9.94612813e-01]\n",
            " [9.99627709e-01 3.70559719e-04 9.26343002e-10 1.66086540e-08\n",
            "  9.88100169e-07 7.01809540e-07]\n",
            " [4.35851143e-05 1.08278414e-06 4.00805984e-05 4.22884732e-05\n",
            "  9.99866843e-01 6.12635722e-06]\n",
            " [8.49231583e-08 2.95978442e-09 7.11003301e-09 4.64376232e-10\n",
            "  1.72686832e-09 9.99999881e-01]\n",
            " [2.07627891e-04 5.68087989e-06 8.42810550e-05 3.46253109e-05\n",
            "  9.99663353e-01 4.35709399e-06]\n",
            " [1.27494670e-04 2.62119238e-06 1.44140518e-04 3.26841873e-05\n",
            "  9.99688029e-01 4.95955010e-06]\n",
            " [9.99870062e-01 2.73334877e-07 7.13102224e-07 1.98679936e-06\n",
            "  3.26387567e-06 1.23681952e-04]\n",
            " [1.24107959e-04 2.83661734e-06 1.85286262e-04 3.65460401e-05\n",
            "  9.99645591e-01 5.60167427e-06]\n",
            " [3.42254789e-05 1.86917714e-05 4.49539766e-05 6.13562315e-06\n",
            "  6.64647378e-05 9.99829412e-01]\n",
            " [2.61288304e-02 3.17259313e-04 2.83699279e-07 9.83791608e-08\n",
            "  2.69044222e-06 9.73550856e-01]\n",
            " [3.38822938e-05 8.70153031e-07 4.74935259e-05 4.05954379e-05\n",
            "  9.99871969e-01 5.10400423e-06]\n",
            " [2.97160179e-04 1.50181195e-05 8.30962381e-05 5.58456122e-05\n",
            "  9.99523759e-01 2.51581259e-05]\n",
            " [9.99043405e-01 5.53257356e-04 1.25318793e-05 2.04052587e-04\n",
            "  1.30001543e-04 5.66470408e-05]\n",
            " [5.54146118e-06 1.39060518e-07 2.01761125e-07 7.37497459e-08\n",
            "  9.99952435e-01 4.16513867e-05]\n",
            " [1.60184336e-05 9.99951839e-01 2.99372323e-06 6.60252726e-06\n",
            "  5.79733580e-07 2.19707599e-05]\n",
            " [9.99303699e-01 7.44052045e-07 5.45193689e-06 1.08281702e-05\n",
            "  5.81970497e-04 9.72604103e-05]\n",
            " [9.99524713e-01 4.73397202e-04 8.38597247e-10 1.66230407e-08\n",
            "  1.66462996e-06 2.16110578e-07]\n",
            " [2.41990056e-05 9.98488545e-01 1.05648331e-04 1.34547683e-03\n",
            "  2.02634801e-05 1.58715939e-05]\n",
            " [8.97809296e-05 2.92300792e-05 3.80382835e-06 9.34430830e-07\n",
            "  4.82852965e-06 9.99871373e-01]\n",
            " [1.02097465e-06 9.99985933e-01 4.49535310e-06 6.70412101e-06\n",
            "  5.06894310e-07 1.27347914e-06]\n",
            " [3.39458302e-06 9.99796689e-01 2.51814384e-07 3.83689240e-07\n",
            "  2.55179802e-05 1.73858847e-04]\n",
            " [4.81177092e-01 5.66909366e-05 3.38211947e-04 2.60903180e-04\n",
            "  5.15635192e-01 2.53191078e-03]\n",
            " [2.28105205e-06 2.03697855e-05 9.99713480e-01 1.22724567e-04\n",
            "  1.39962314e-04 1.13744932e-06]]\n",
            "Histórico\n",
            "          loss  accuracy    recall  precision  true_positives  true_negatives  \\\n",
            "0     1.668609  0.348740  0.096639   0.469388            23.0          1164.0   \n",
            "1     1.178841  0.533613  0.336134   0.625000            80.0          1142.0   \n",
            "2     1.055113  0.563025  0.365546   0.664122            87.0          1146.0   \n",
            "3     0.967643  0.600840  0.462185   0.743243           110.0          1152.0   \n",
            "4     0.967540  0.605042  0.428571   0.718310           102.0          1150.0   \n",
            "...        ...       ...       ...        ...             ...             ...   \n",
            "1495  0.005435  1.000000  1.000000   1.000000           238.0          1190.0   \n",
            "1496  0.009568  0.995798  0.995798   0.995798           237.0          1189.0   \n",
            "1497  0.003615  1.000000  1.000000   1.000000           238.0          1190.0   \n",
            "1498  0.005848  1.000000  1.000000   1.000000           238.0          1190.0   \n",
            "1499  0.007919  1.000000  1.000000   1.000000           238.0          1190.0   \n",
            "\n",
            "      false_positives  false_negatives      lr  \n",
            "0                26.0            215.0  0.0010  \n",
            "1                48.0            158.0  0.0010  \n",
            "2                44.0            151.0  0.0010  \n",
            "3                38.0            128.0  0.0010  \n",
            "4                40.0            136.0  0.0010  \n",
            "...               ...              ...     ...  \n",
            "1495              0.0              0.0  0.0001  \n",
            "1496              1.0              1.0  0.0001  \n",
            "1497              0.0              0.0  0.0001  \n",
            "1498              0.0              0.0  0.0001  \n",
            "1499              0.0              0.0  0.0001  \n",
            "\n",
            "[1500 rows x 9 columns]\n",
            "Temp: 0.9818627450980393\n",
            "   precision  accuracy    recall  f1_score   duration  std  specificity\n",
            "0   0.981863     0.975  0.979167  0.979565  569.66209  0.0     0.994664\n",
            "\t\t\t\tDONE\n",
            "\t\titer 3\n",
            "\t\t\tdataset_name:  AllCandidas\n",
            "valor de x_train no prepare data [[1.993e+04 5.877e+04 1.544e+04 ... 1.188e+03 4.239e+03 4.000e+00]\n",
            " [8.122e+04 7.305e+03 6.886e+03 ... 1.055e+04 7.302e+03 4.000e+00]\n",
            " [8.223e+04 7.305e+03 6.032e+03 ... 1.834e+04 7.841e+03 6.000e+00]\n",
            " ...\n",
            " [2.606e+04 4.686e+04 2.178e+04 ... 2.586e+03 5.592e+03 4.000e+00]\n",
            " [3.245e+04 4.572e+04 2.271e+04 ... 2.613e+03 5.596e+03 5.000e+00]\n",
            " [6.787e+04 1.842e+04 2.108e+04 ... 1.091e+04 6.971e+03 2.000e+00]]\n",
            "valor de y_train no prepare data [1. 6. 1. 2. 5. 1. 2. 2. 1. 2. 4. 5. 3. 1. 3. 5. 2. 5. 1. 6. 2. 6. 1. 5.\n",
            " 1. 2. 2. 6. 6. 5. 2. 1. 5. 4. 1. 1. 1. 6. 1. 1. 5. 6. 1. 2. 6. 4. 2. 2.\n",
            " 1. 6. 5. 5. 5. 6. 5. 2. 6. 5. 2. 2. 6. 6. 6. 2. 4. 5. 5. 3. 6. 4. 2. 1.\n",
            " 5. 5. 1. 6. 5. 5. 2. 2. 1. 1. 1. 4. 6. 1. 5. 5. 4. 5. 4. 2. 2. 6. 4. 5.\n",
            " 2. 4. 5. 3. 2. 6. 5. 2. 1. 5. 6. 2. 6. 6. 4. 5. 6. 5. 5. 6. 2. 4. 2. 2.\n",
            " 1. 3. 1. 2. 6. 2. 6. 5. 5. 6. 5. 6. 6. 3. 3. 4. 5. 2. 6. 2. 6. 2. 2. 4.\n",
            " 5. 4. 6. 6. 1. 6. 4. 2. 5. 5. 5. 1. 5. 6. 1. 5. 6. 1. 3. 3. 1. 6. 3. 1.\n",
            " 6. 4. 2. 2. 2. 1. 6. 6. 4. 2. 2. 2. 1. 2. 4. 6. 3. 1. 2. 1. 6. 2. 6. 1.\n",
            " 5. 2. 5. 1. 5. 1. 5. 1. 5. 1. 3. 3. 2. 1. 2. 1. 6. 4. 1. 1. 6. 2. 6. 2.\n",
            " 2. 2. 6. 6. 1. 5. 3. 6. 2. 1. 2. 1. 6. 5. 6. 6. 2. 4. 1. 3. 5. 6.]\n",
            "valor de y_val no prepare data [6. 3. 2. 2. 2. 2. 6. 2. 5. 1. 2. 3. 2. 2. 1. 2. 5. 2. 2. 2. 1. 1. 1. 2.\n",
            " 5. 1. 6. 3. 2. 6. 2. 4. 1. 6. 6. 1. 6. 3. 6. 6. 6. 4. 6. 5. 1. 4. 2. 5.\n",
            " 2. 5. 3. 6. 2. 6. 3. 2. 3. 3. 3. 6. 5. 4. 1. 5. 2. 6. 6. 1. 6. 6. 2. 6.\n",
            " 4. 6. 1. 3. 5. 6. 2.]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-15-c033a5082e59>:21: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  df_best_model = pd.DataFrame(data=np.zeros((1, 6), dtype=np.float), index=[0],\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dentro do FitModel\n",
            "2/2 [==============================] - 1s 31ms/step\n",
            "y_pred before save =  \n",
            " [[5.36668767e-06 9.99824584e-01 2.00783907e-05 1.24581202e-04\n",
            "  8.85448662e-06 1.65088368e-05]\n",
            " [2.20303864e-05 9.99112904e-01 7.74455548e-05 7.18619383e-04\n",
            "  3.02672652e-05 3.87314030e-05]\n",
            " [3.56883362e-07 2.87434923e-05 9.99933958e-01 2.02583760e-05\n",
            "  1.60823583e-05 5.81482823e-07]\n",
            " [3.66638892e-06 1.96589444e-05 3.71639362e-05 9.99871016e-01\n",
            "  6.75920310e-05 7.91896582e-07]\n",
            " [1.36268980e-04 1.40040764e-04 4.42302335e-05 1.48386453e-05\n",
            "  2.12391060e-05 9.99643445e-01]\n",
            " [3.93586088e-04 1.60897675e-04 1.15656496e-06 6.56164138e-06\n",
            "  1.93607135e-04 9.99244213e-01]\n",
            " [5.72069666e-06 9.99661207e-01 5.13078749e-06 2.76034494e-04\n",
            "  4.71088242e-05 4.86772569e-06]\n",
            " [1.56448004e-04 1.68730752e-04 6.82825703e-05 1.69695522e-05\n",
            "  2.16078988e-05 9.99568045e-01]\n",
            " [9.98666525e-01 1.15827785e-03 8.25642019e-06 1.05473060e-04\n",
            "  3.12071934e-05 3.03891320e-05]\n",
            " [1.62296953e-06 9.99987602e-01 1.95549443e-09 1.27521434e-06\n",
            "  8.84857673e-06 5.42455268e-07]\n",
            " [5.40633346e-06 1.77919246e-05 7.40592586e-05 9.99841571e-01\n",
            "  5.99717496e-05 1.14680824e-06]\n",
            " [1.24254007e-06 9.99961495e-01 3.90549353e-08 2.20868628e-06\n",
            "  2.72621310e-05 7.82437473e-06]\n",
            " [9.99996305e-01 1.61759851e-06 2.99417990e-11 1.69425584e-06\n",
            "  1.33593602e-07 2.08079371e-07]\n",
            " [4.41609009e-04 1.07857177e-05 1.38689416e-06 3.31895581e-06\n",
            "  9.99541044e-01 1.94207814e-06]\n",
            " [5.79801872e-06 9.99830723e-01 1.47009250e-05 1.23734775e-04\n",
            "  8.50620654e-06 1.65285055e-05]\n",
            " [6.30979566e-03 9.93661880e-01 1.36198150e-06 5.68141786e-07\n",
            "  2.95892232e-06 2.34455092e-05]\n",
            " [1.76009362e-05 8.55021499e-05 4.00059025e-06 9.99888420e-01\n",
            "  3.21820903e-06 1.17312550e-06]\n",
            " [7.15631127e-01 5.62707782e-02 1.80889390e-06 1.65968504e-05\n",
            "  3.54344120e-05 2.28044286e-01]\n",
            " [9.57961820e-05 9.99773681e-01 5.12035342e-07 7.06581923e-05\n",
            "  1.35993896e-05 4.57533752e-05]\n",
            " [9.99985218e-01 4.67019572e-06 5.91175331e-10 6.95360222e-06\n",
            "  2.86067643e-06 4.05406837e-07]\n",
            " [3.14898571e-05 1.40363602e-06 2.82795190e-05 1.11824666e-05\n",
            "  9.99927163e-01 5.35464835e-07]\n",
            " [2.58627006e-05 2.05118181e-06 5.30775696e-06 2.50639664e-06\n",
            "  9.99963880e-01 3.12681550e-07]\n",
            " [3.31201591e-06 1.89892835e-05 2.59274711e-05 9.99905348e-01\n",
            "  4.56523012e-05 6.86162537e-07]\n",
            " [4.34282738e-05 4.29377724e-06 1.26730470e-07 6.19225318e-07\n",
            "  9.96207118e-01 3.74439056e-03]\n",
            " [2.18627145e-04 5.99584473e-06 2.08768997e-05 4.13122652e-05\n",
            "  9.99711692e-01 1.48392837e-06]\n",
            " [9.99859333e-01 4.27599389e-06 2.22041352e-12 1.15593956e-07\n",
            "  1.36082948e-04 1.13818011e-07]\n",
            " [9.57138300e-01 8.31496436e-04 5.20231652e-07 7.64108881e-06\n",
            "  3.58103171e-05 4.19861861e-02]\n",
            " [9.99973178e-01 4.65327230e-06 3.03059633e-10 2.14149950e-05\n",
            "  5.39510268e-07 2.23675087e-07]\n",
            " [1.90173050e-05 1.03980041e-04 6.69460434e-08 4.44825264e-06\n",
            "  2.33741002e-06 9.99870062e-01]\n",
            " [5.76004565e-01 9.55107361e-02 5.34130004e-06 1.13771879e-04\n",
            "  2.12381201e-04 3.28153133e-01]\n",
            " [4.12888112e-05 2.20657603e-06 7.47523245e-07 1.03253490e-06\n",
            "  9.96468306e-01 3.48648266e-03]\n",
            " [1.97400316e-03 3.37386824e-04 2.04969347e-05 8.37441330e-05\n",
            "  3.01181281e-04 9.97283220e-01]\n",
            " [6.10673014e-05 7.46721298e-06 3.51001040e-06 2.74485296e-06\n",
            "  9.99924779e-01 5.24872405e-07]\n",
            " [6.73610339e-05 9.95955229e-01 9.65410363e-05 3.71666648e-03\n",
            "  1.22305530e-04 4.19668613e-05]\n",
            " [1.70627376e-04 1.34981354e-04 2.32495258e-05 1.77474394e-05\n",
            "  5.20467984e-05 9.99601305e-01]\n",
            " [3.71881179e-05 1.46293007e-06 2.78197494e-05 1.40562606e-05\n",
            "  9.99918818e-01 5.89742228e-07]\n",
            " [7.49201427e-05 3.98079828e-06 5.02868443e-06 4.59960620e-06\n",
            "  9.99910831e-01 6.01047361e-07]\n",
            " [6.90261185e-01 5.71021102e-02 3.82043618e-06 7.09630622e-05\n",
            "  1.41215758e-04 2.52420664e-01]\n",
            " [6.56579459e-07 1.63899131e-05 9.99909520e-01 3.10936048e-05\n",
            "  4.15252653e-05 7.83919972e-07]\n",
            " [3.52817466e-07 3.39470571e-05 9.99927640e-01 2.29049128e-05\n",
            "  1.45143449e-05 5.97249709e-07]\n",
            " [9.75152493e-01 2.94448604e-04 1.57438947e-07 1.36251344e-06\n",
            "  3.29858158e-05 2.45185159e-02]\n",
            " [4.80893155e-04 2.11894276e-05 1.06595508e-05 2.21100327e-05\n",
            "  9.99462783e-01 2.42604938e-06]\n",
            " [8.29114924e-06 9.99988675e-01 1.03418039e-08 4.55870548e-07\n",
            "  5.17959165e-07 2.02525985e-06]\n",
            " [8.69662836e-06 4.04272505e-05 2.78297284e-06 1.53083579e-06\n",
            "  9.99932647e-01 1.39037611e-05]\n",
            " [6.03223225e-06 9.99967694e-01 9.51362455e-09 3.72087197e-06\n",
            "  1.70677486e-05 5.48166781e-06]\n",
            " [9.99911427e-01 4.31743956e-06 5.45043157e-08 2.21663026e-06\n",
            "  7.78616538e-07 8.12548533e-05]\n",
            " [2.85848364e-05 2.66357279e-06 6.31934967e-08 3.76600866e-07\n",
            "  9.96568799e-01 3.39942216e-03]\n",
            " [9.99995947e-01 1.09469272e-06 1.43509604e-09 2.50872120e-07\n",
            "  1.11743600e-06 1.64257790e-06]\n",
            " [7.50834806e-06 9.99936700e-01 8.53516383e-07 1.87888600e-05\n",
            "  3.47081686e-06 3.26620902e-05]\n",
            " [9.89186356e-06 9.99056399e-01 2.05093733e-04 4.04722407e-04\n",
            "  3.11081531e-04 1.28090833e-05]\n",
            " [7.35438821e-10 1.00000000e+00 3.19941881e-12 4.27912636e-11\n",
            "  5.25128696e-09 2.69137223e-15]\n",
            " [8.16461693e-07 1.13621267e-04 9.99828219e-01 2.26709180e-05\n",
            "  3.34332108e-05 1.24806286e-06]\n",
            " [1.32602762e-09 1.00000000e+00 6.20413172e-13 4.17282320e-11\n",
            "  3.08687831e-09 4.66626114e-14]\n",
            " [2.20267666e-05 5.22621031e-06 3.23564890e-08 2.33854576e-06\n",
            "  1.02789745e-04 9.99867558e-01]\n",
            " [9.99988198e-01 3.63517574e-06 4.53524551e-10 5.23525159e-06\n",
            "  2.56952808e-06 3.81674624e-07]\n",
            " [1.43944790e-05 9.99868035e-01 2.87535636e-06 5.47795171e-05\n",
            "  9.78819389e-06 5.00440801e-05]\n",
            " [6.21487619e-04 9.92248184e-04 1.56524959e-06 1.52470448e-05\n",
            "  1.52588502e-04 9.98216927e-01]\n",
            " [2.15767935e-01 1.07899898e-04 1.65080053e-07 2.12455348e-07\n",
            "  1.35980617e-05 7.84110248e-01]\n",
            " [9.99935865e-01 6.33617528e-05 1.72574524e-11 5.58837385e-08\n",
            "  4.25634596e-07 2.95908734e-07]\n",
            " [2.49339268e-04 7.08207244e-06 2.38141947e-05 5.03505034e-05\n",
            "  9.99667764e-01 1.66404436e-06]\n",
            " [1.26570853e-07 1.43959777e-09 2.08135162e-10 7.90014582e-11\n",
            "  9.82847762e-11 9.99999881e-01]\n",
            " [4.60688061e-05 1.74486888e-06 1.45953627e-05 9.55849009e-06\n",
            "  9.99927402e-01 5.99831878e-07]\n",
            " [4.36042865e-05 1.88766046e-06 4.36291193e-05 2.00456452e-05\n",
            "  9.99889970e-01 7.82361667e-07]\n",
            " [9.99791086e-01 2.51926008e-06 2.03525587e-08 1.37250663e-06\n",
            "  4.59744570e-06 2.00456809e-04]\n",
            " [4.47760904e-05 2.17143656e-06 6.24529857e-05 2.27953315e-05\n",
            "  9.99866962e-01 8.76770912e-07]\n",
            " [1.70162384e-04 1.24381317e-04 2.05636970e-05 1.57202794e-05\n",
            "  4.54857945e-05 9.99623656e-01]\n",
            " [6.13660276e-01 3.65228880e-05 6.65031550e-08 1.91313035e-07\n",
            "  1.63453606e-05 3.86286557e-01]\n",
            " [1.36373637e-04 4.98034024e-06 2.32219209e-05 3.64244261e-05\n",
            "  9.99798000e-01 1.12685268e-06]\n",
            " [1.04679866e-03 2.81344091e-05 1.77027723e-05 6.25735265e-05\n",
            "  9.98840392e-01 4.43487852e-06]\n",
            " [9.99990821e-01 2.99152248e-06 1.03852843e-10 5.76183629e-06\n",
            "  3.03881620e-07 2.05965335e-07]\n",
            " [2.78284424e-05 1.87989224e-06 3.12582955e-07 5.82055861e-07\n",
            "  9.98638570e-01 1.33086427e-03]\n",
            " [1.78614137e-05 9.99910474e-01 4.53784196e-07 2.87334733e-05\n",
            "  4.90220145e-06 3.74768351e-05]\n",
            " [9.99628067e-01 3.05953836e-06 1.22840831e-07 6.35798870e-06\n",
            "  2.39169298e-04 1.23248203e-04]\n",
            " [9.99951243e-01 4.76577297e-05 1.25419128e-11 4.72805155e-08\n",
            "  8.22716913e-07 2.21416485e-07]\n",
            " [8.47912597e-05 9.95042205e-01 1.14817361e-04 4.62062005e-03\n",
            "  7.35456415e-05 6.39474310e-05]\n",
            " [3.30999354e-03 4.35109570e-04 2.16356784e-05 1.42959543e-04\n",
            "  3.30580107e-04 9.95759666e-01]\n",
            " [3.30175158e-06 9.99917030e-01 5.74873229e-06 5.85481139e-05\n",
            "  4.60670253e-06 1.07945298e-05]\n",
            " [1.97438603e-05 9.99942183e-01 1.15055299e-08 6.92365847e-06\n",
            "  1.96948713e-05 1.13660171e-05]\n",
            " [8.79560828e-01 1.70187748e-04 1.73456447e-05 2.16160828e-04\n",
            "  1.18068099e-01 1.96738332e-03]\n",
            " [1.53722328e-06 2.29862144e-05 9.99777377e-01 5.94420198e-05\n",
            "  1.37240670e-04 1.37218160e-06]]\n",
            "Histórico\n",
            "          loss  accuracy    recall  precision  true_positives  true_negatives  \\\n",
            "0     1.783121  0.331933  0.142857   0.492754            34.0          1155.0   \n",
            "1     1.239226  0.537815  0.348740   0.601449            83.0          1135.0   \n",
            "2     1.043871  0.529412  0.323529   0.785714            77.0          1169.0   \n",
            "3     0.946196  0.621849  0.453782   0.705882           108.0          1145.0   \n",
            "4     0.874909  0.638655  0.483193   0.714286           115.0          1144.0   \n",
            "...        ...       ...       ...        ...             ...             ...   \n",
            "1495  0.009887  0.995798  0.995798   0.995798           237.0          1189.0   \n",
            "1496  0.004703  1.000000  1.000000   1.000000           238.0          1190.0   \n",
            "1497  0.011543  0.991597  0.991597   0.991597           236.0          1188.0   \n",
            "1498  0.006987  1.000000  1.000000   1.000000           238.0          1190.0   \n",
            "1499  0.004397  1.000000  1.000000   1.000000           238.0          1190.0   \n",
            "\n",
            "      false_positives  false_negatives      lr  \n",
            "0                35.0            204.0  0.0010  \n",
            "1                55.0            155.0  0.0010  \n",
            "2                21.0            161.0  0.0010  \n",
            "3                45.0            130.0  0.0010  \n",
            "4                46.0            123.0  0.0010  \n",
            "...               ...              ...     ...  \n",
            "1495              1.0              1.0  0.0001  \n",
            "1496              0.0              0.0  0.0001  \n",
            "1497              2.0              2.0  0.0001  \n",
            "1498              0.0              0.0  0.0001  \n",
            "1499              0.0              0.0  0.0001  \n",
            "\n",
            "[1500 rows x 9 columns]\n",
            "Temp: 0.9500000000000001\n",
            "   precision  accuracy    recall  f1_score    duration  std  specificity\n",
            "0       0.95     0.925  0.939583  0.939866  550.988017  0.0     0.984247\n",
            "\t\t\t\tDONE\n",
            "\t\titer 4\n",
            "\t\t\tdataset_name:  AllCandidas\n",
            "valor de x_train no prepare data [[1.993e+04 5.877e+04 1.544e+04 ... 1.188e+03 4.239e+03 4.000e+00]\n",
            " [8.122e+04 7.305e+03 6.886e+03 ... 1.055e+04 7.302e+03 4.000e+00]\n",
            " [8.223e+04 7.305e+03 6.032e+03 ... 1.834e+04 7.841e+03 6.000e+00]\n",
            " ...\n",
            " [2.606e+04 4.686e+04 2.178e+04 ... 2.586e+03 5.592e+03 4.000e+00]\n",
            " [3.245e+04 4.572e+04 2.271e+04 ... 2.613e+03 5.596e+03 5.000e+00]\n",
            " [6.787e+04 1.842e+04 2.108e+04 ... 1.091e+04 6.971e+03 2.000e+00]]\n",
            "valor de y_train no prepare data [1. 6. 1. 2. 5. 1. 2. 2. 1. 2. 4. 5. 3. 1. 3. 5. 2. 5. 1. 6. 2. 6. 1. 5.\n",
            " 1. 2. 2. 6. 6. 5. 2. 1. 5. 4. 1. 1. 1. 6. 1. 1. 5. 6. 1. 2. 6. 4. 2. 2.\n",
            " 1. 6. 5. 5. 5. 6. 5. 2. 6. 5. 2. 2. 6. 6. 6. 2. 4. 5. 5. 3. 6. 4. 2. 1.\n",
            " 5. 5. 1. 6. 5. 5. 2. 2. 1. 1. 1. 4. 6. 1. 5. 5. 4. 5. 4. 2. 2. 6. 4. 5.\n",
            " 2. 4. 5. 3. 2. 6. 5. 2. 1. 5. 6. 2. 6. 6. 4. 5. 6. 5. 5. 6. 2. 4. 2. 2.\n",
            " 1. 3. 1. 2. 6. 2. 6. 5. 5. 6. 5. 6. 6. 3. 3. 4. 5. 2. 6. 2. 6. 2. 2. 4.\n",
            " 5. 4. 6. 6. 1. 6. 4. 2. 5. 5. 5. 1. 5. 6. 1. 5. 6. 1. 3. 3. 1. 6. 3. 1.\n",
            " 6. 4. 2. 2. 2. 1. 6. 6. 4. 2. 2. 2. 1. 2. 4. 6. 3. 1. 2. 1. 6. 2. 6. 1.\n",
            " 5. 2. 5. 1. 5. 1. 5. 1. 5. 1. 3. 3. 2. 1. 2. 1. 6. 4. 1. 1. 6. 2. 6. 2.\n",
            " 2. 2. 6. 6. 1. 5. 3. 6. 2. 1. 2. 1. 6. 5. 6. 6. 2. 4. 1. 3. 5. 6.]\n",
            "valor de y_val no prepare data [6. 3. 2. 2. 2. 2. 6. 2. 5. 1. 2. 3. 2. 2. 1. 2. 5. 2. 2. 2. 1. 1. 1. 2.\n",
            " 5. 1. 6. 3. 2. 6. 2. 4. 1. 6. 6. 1. 6. 3. 6. 6. 6. 4. 6. 5. 1. 4. 2. 5.\n",
            " 2. 5. 3. 6. 2. 6. 3. 2. 3. 3. 3. 6. 5. 4. 1. 5. 2. 6. 6. 1. 6. 6. 2. 6.\n",
            " 4. 6. 1. 3. 5. 6. 2.]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-15-c033a5082e59>:21: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  df_best_model = pd.DataFrame(data=np.zeros((1, 6), dtype=np.float), index=[0],\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dentro do FitModel\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 9 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f14e6365550> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 1s 24ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-15-c033a5082e59>:21: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  df_best_model = pd.DataFrame(data=np.zeros((1, 6), dtype=np.float), index=[0],\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "y_pred before save =  \n",
            " [[6.20293167e-06 9.99947071e-01 4.27609984e-06 2.12385494e-05\n",
            "  7.63181015e-06 1.36348408e-05]\n",
            " [1.51685454e-05 9.99830365e-01 1.59031715e-05 9.42296028e-05\n",
            "  2.03373620e-05 2.39562305e-05]\n",
            " [1.42897989e-07 2.36130491e-05 9.99881983e-01 6.69390211e-05\n",
            "  2.68059011e-05 4.84763859e-07]\n",
            " [3.89662944e-07 6.40114886e-05 1.40712646e-05 9.99915600e-01\n",
            "  5.97740200e-06 2.46552325e-08]\n",
            " [2.90662410e-05 3.16798178e-05 4.00799399e-05 7.80415576e-07\n",
            "  3.08368035e-05 9.99867558e-01]\n",
            " [1.89983421e-05 2.96841481e-05 6.01847432e-06 1.91710728e-06\n",
            "  7.05319631e-04 9.99238133e-01]\n",
            " [2.95738459e-06 9.99949217e-01 5.13729674e-07 1.84370710e-05\n",
            "  2.56761887e-05 3.14138060e-06]\n",
            " [3.28321512e-05 4.72169741e-05 8.01341594e-05 1.26592079e-06\n",
            "  3.76090575e-05 9.99800861e-01]\n",
            " [9.99979377e-01 1.47147603e-06 4.95750534e-08 8.12656751e-08\n",
            "  4.14342730e-06 1.49431544e-05]\n",
            " [2.65257731e-05 9.99727070e-01 3.47833193e-08 4.79992468e-06\n",
            "  6.88640575e-05 1.72592088e-04]\n",
            " [4.78489540e-07 2.38509056e-05 4.41721786e-05 9.99925494e-01\n",
            "  5.96916107e-06 2.80437042e-08]\n",
            " [2.24783289e-04 9.99366701e-01 6.92014126e-08 1.23727650e-05\n",
            "  8.39372442e-05 3.12190852e-04]\n",
            " [9.99977112e-01 1.27535732e-05 3.36669403e-09 4.41280781e-06\n",
            "  4.12774443e-06 1.59246667e-06]\n",
            " [2.75948871e-04 9.84865255e-06 2.33146056e-06 1.89039486e-06\n",
            "  9.99705732e-01 4.17629508e-06]\n",
            " [6.36845607e-06 9.99952078e-01 2.95547898e-06 1.83703960e-05\n",
            "  6.98928579e-06 1.32897467e-05]\n",
            " [1.25291676e-03 9.96453404e-01 9.02413649e-06 6.91552259e-06\n",
            "  2.06385259e-04 2.07133079e-03]\n",
            " [4.41804150e-06 5.04576135e-04 7.99033296e-06 9.99481261e-01\n",
            "  1.37300549e-06 3.55005170e-07]\n",
            " [5.70291770e-04 2.47472453e-05 5.72873304e-08 5.40984235e-09\n",
            "  1.70260179e-08 9.99404907e-01]\n",
            " [6.83711187e-05 9.99857783e-01 2.04795128e-07 5.38903805e-06\n",
            "  3.64699326e-06 6.45477194e-05]\n",
            " [9.99921918e-01 1.59048395e-05 2.24389254e-08 6.75765477e-06\n",
            "  5.27760603e-05 2.66672987e-06]\n",
            " [6.78554279e-05 1.89282673e-05 1.62993863e-04 1.51648110e-05\n",
            "  9.99731004e-01 4.02643809e-06]\n",
            " [1.27229941e-04 3.97631084e-05 4.92258878e-05 1.17359759e-05\n",
            "  9.99765694e-01 6.25772418e-06]\n",
            " [3.50164640e-07 5.07071636e-05 8.35317223e-06 9.99937057e-01\n",
            "  3.52520647e-06 2.27784209e-08]\n",
            " [2.34346047e-07 1.48645154e-06 3.72571662e-07 3.12140322e-08\n",
            "  9.99920011e-01 7.78061440e-05]\n",
            " [4.88367659e-05 2.01934854e-05 4.09529021e-05 1.03244802e-05\n",
            "  9.99879360e-01 4.08988058e-07]\n",
            " [9.99997377e-01 1.05513884e-07 6.35865601e-14 3.94197430e-09\n",
            "  2.45329602e-06 6.00854655e-09]\n",
            " [8.30271840e-03 2.37685481e-06 7.37184450e-07 1.51882986e-08\n",
            "  3.93819235e-08 9.91694152e-01]\n",
            " [9.99755561e-01 9.97584939e-05 7.70323680e-08 1.12200643e-04\n",
            "  2.76931914e-05 4.67454538e-06]\n",
            " [1.54782465e-05 1.35775781e-05 2.22285053e-06 1.54351369e-06\n",
            "  3.85246909e-04 9.99581993e-01]\n",
            " [1.99389789e-04 6.83111011e-06 1.70320618e-07 8.00338995e-09\n",
            "  1.34650877e-08 9.99793589e-01]\n",
            " [4.04194473e-08 8.02536363e-07 7.83235748e-07 1.14641088e-08\n",
            "  9.99940395e-01 5.79151092e-05]\n",
            " [7.70312545e-05 6.67776912e-05 3.14712634e-06 4.82310952e-07\n",
            "  1.00586049e-05 9.99842525e-01]\n",
            " [8.07680190e-05 5.81405257e-05 2.18538680e-05 6.36531058e-06\n",
            "  9.99831915e-01 9.38980008e-07]\n",
            " [3.03803026e-05 9.99412894e-01 2.01250150e-05 4.26837592e-04\n",
            "  8.26594405e-05 2.70242035e-05]\n",
            " [9.21274695e-05 4.69492661e-05 9.68087170e-06 5.88267199e-07\n",
            "  4.89837621e-05 9.99801695e-01]\n",
            " [8.30191566e-05 2.18394853e-05 1.54786947e-04 1.86480647e-05\n",
            "  9.99717176e-01 4.48058336e-06]\n",
            " [5.31089645e-05 1.71929423e-05 2.02015162e-05 3.76486673e-06\n",
            "  9.99905109e-01 5.60429044e-07]\n",
            " [1.30480315e-04 3.68327574e-06 1.14842450e-07 4.46816184e-09\n",
            "  7.46577022e-09 9.99865651e-01]\n",
            " [2.37515820e-07 1.71986594e-05 9.99777973e-01 1.19814176e-04\n",
            "  8.40316279e-05 7.97289260e-07]\n",
            " [1.39842584e-07 2.68514814e-05 9.99869108e-01 7.89268379e-05\n",
            "  2.45925057e-05 4.91014703e-07]\n",
            " [6.18783593e-01 5.19565190e-04 8.93809556e-06 1.22006088e-06\n",
            "  5.74951537e-06 3.80680889e-01]\n",
            " [4.45309095e-04 1.04510902e-04 4.61918826e-05 2.66667175e-05\n",
            "  9.99374211e-01 3.04901619e-06]\n",
            " [1.58658331e-05 9.99975562e-01 3.49984797e-09 3.23626992e-08\n",
            "  3.58088357e-07 8.22149923e-06]\n",
            " [2.58318487e-05 1.14967363e-04 4.11305591e-05 3.59051029e-07\n",
            "  9.99589503e-01 2.28245131e-04]\n",
            " [1.24425103e-04 9.96595919e-01 3.95532822e-07 2.25750100e-05\n",
            "  1.90353065e-04 3.06639588e-03]\n",
            " [9.99996424e-01 8.90602081e-08 8.20712220e-10 7.08719439e-09\n",
            "  2.03675441e-07 3.21119819e-06]\n",
            " [3.57741044e-07 1.56710485e-06 3.03957648e-07 3.71037459e-08\n",
            "  9.99909163e-01 8.85828122e-05]\n",
            " [9.99994278e-01 2.12891749e-07 1.14585709e-10 1.51324198e-09\n",
            "  1.30076252e-08 5.47267200e-06]\n",
            " [1.73266326e-05 9.99922395e-01 2.75486002e-07 4.03713329e-06\n",
            "  1.30600881e-06 5.47687050e-05]\n",
            " [3.06316520e-06 9.99796212e-01 1.18515418e-05 5.38124659e-05\n",
            "  1.30635352e-04 4.42196779e-06]\n",
            " [2.51189722e-05 9.99386311e-01 4.80603474e-11 2.18742668e-09\n",
            "  5.88567054e-04 4.92145436e-10]\n",
            " [2.98578300e-07 6.61463564e-05 9.99835253e-01 5.94965059e-05\n",
            "  3.77900869e-05 1.04659466e-06]\n",
            " [3.61019694e-08 9.99998689e-01 3.71465418e-14 2.41807911e-11\n",
            "  1.33189076e-06 7.95611233e-12]\n",
            " [4.28763633e-05 2.22293547e-05 7.08169864e-06 5.02509147e-06\n",
            "  1.17983241e-02 9.88124490e-01]\n",
            " [9.99940515e-01 1.07194028e-05 1.46421373e-08 4.96551229e-06\n",
            "  4.14002898e-05 2.37244376e-06]\n",
            " [2.47873322e-05 9.99892235e-01 8.92436219e-07 1.56764399e-05\n",
            "  2.86776890e-06 6.34959433e-05]\n",
            " [3.14783974e-05 5.13222039e-05 6.46682111e-06 3.03095817e-06\n",
            "  6.54199859e-04 9.99253452e-01]\n",
            " [1.21999532e-02 7.65369332e-05 4.06325898e-06 1.73162348e-07\n",
            "  6.70076815e-07 9.87718582e-01]\n",
            " [9.99851227e-01 1.48329360e-04 5.35207425e-12 8.36609093e-09\n",
            "  1.21143913e-07 3.56107904e-07]\n",
            " [4.87746474e-05 2.31124195e-05 4.49148902e-05 1.15172134e-05\n",
            "  9.99871254e-01 4.17024182e-07]\n",
            " [1.20839454e-08 6.92584434e-09 3.21078830e-09 2.05246983e-11\n",
            "  1.44328965e-10 1.00000000e+00]\n",
            " [1.28148851e-04 2.47436947e-05 7.42664488e-05 1.62251927e-05\n",
            "  9.99751508e-01 5.11499093e-06]\n",
            " [9.14007251e-05 2.13903531e-05 1.99834307e-04 2.20737766e-05\n",
            "  9.99660134e-01 5.11647522e-06]\n",
            " [9.99076843e-01 1.01251435e-05 2.85440706e-07 1.34906350e-05\n",
            "  2.24655214e-05 8.76711740e-04]\n",
            " [8.91491145e-05 2.46882464e-05 2.90668628e-04 2.47671760e-05\n",
            "  9.99565184e-01 5.51728272e-06]\n",
            " [7.97722460e-05 4.10106732e-05 9.12687210e-06 5.26588906e-07\n",
            "  4.44848374e-05 9.99825180e-01]\n",
            " [6.54527321e-02 7.54423017e-05 4.68281587e-06 2.71286808e-07\n",
            "  1.11676866e-06 9.34465826e-01]\n",
            " [2.88541196e-05 2.10270009e-05 5.61015804e-05 1.02129507e-05\n",
            "  9.99883413e-01 2.98009809e-07]\n",
            " [7.07963016e-04 1.00628735e-04 5.13412597e-05 4.19862445e-05\n",
            "  9.99094725e-01 3.28214355e-06]\n",
            " [9.99942899e-01 2.88942229e-05 1.31140983e-08 1.63777258e-05\n",
            "  9.50207777e-06 2.32980392e-06]\n",
            " [3.21655200e-08 6.11137239e-07 4.52653410e-07 8.84210216e-09\n",
            "  9.99975204e-01 2.36808337e-05]\n",
            " [3.37326637e-05 9.99888301e-01 1.97517409e-07 3.69855456e-06\n",
            "  1.79197514e-06 7.22534896e-05]\n",
            " [9.97652352e-01 2.47738481e-05 3.73336002e-06 2.95483096e-05\n",
            "  1.37004873e-03 9.19626968e-04]\n",
            " [9.99854207e-01 1.45498998e-04 3.23425379e-12 7.17298621e-09\n",
            "  1.29398430e-07 9.06648765e-08]\n",
            " [3.69180561e-05 9.99310017e-01 2.89397576e-05 5.37976681e-04\n",
            "  4.93213229e-05 3.67496541e-05]\n",
            " [1.23298814e-04 1.21299177e-04 3.09786697e-06 5.95510642e-07\n",
            "  8.74630950e-06 9.99743044e-01]\n",
            " [4.57579972e-06 9.99970555e-01 1.25479062e-06 8.88223622e-06\n",
            "  4.34848926e-06 1.04156288e-05]\n",
            " [1.69858205e-04 9.96689796e-01 2.45064058e-07 2.46338313e-05\n",
            "  9.16728895e-05 3.02378810e-03]\n",
            " [6.51951730e-01 8.85676767e-04 2.79484928e-04 2.40618669e-04\n",
            "  3.32329571e-01 1.43129574e-02]\n",
            " [5.63120579e-07 2.57241190e-05 9.99575078e-01 1.57270362e-04\n",
            "  2.39733432e-04 1.59547244e-06]]\n",
            "Histórico\n",
            "          loss  accuracy    recall  precision  true_positives  true_negatives  \\\n",
            "0     1.750465  0.331933  0.176471   0.350000            42.0          1112.0   \n",
            "1     1.206696  0.542017  0.210084   0.595238            50.0          1156.0   \n",
            "2     1.001204  0.596639  0.348740   0.715517            83.0          1157.0   \n",
            "3     0.974045  0.575630  0.441176   0.632530           105.0          1129.0   \n",
            "4     0.919812  0.596639  0.357143   0.758929            85.0          1163.0   \n",
            "...        ...       ...       ...        ...             ...             ...   \n",
            "1495  0.060199  0.970588  0.970588   0.978814           231.0          1185.0   \n",
            "1496  0.048978  0.983193  0.978992   0.983122           233.0          1186.0   \n",
            "1497  0.017712  0.995798  0.995798   0.995798           237.0          1189.0   \n",
            "1498  0.023082  0.987395  0.987395   0.991561           235.0          1188.0   \n",
            "1499  0.009476  1.000000  1.000000   1.000000           238.0          1190.0   \n",
            "\n",
            "      false_positives  false_negatives      lr  \n",
            "0                78.0            196.0  0.0010  \n",
            "1                34.0            188.0  0.0010  \n",
            "2                33.0            155.0  0.0010  \n",
            "3                61.0            133.0  0.0010  \n",
            "4                27.0            153.0  0.0010  \n",
            "...               ...              ...     ...  \n",
            "1495              5.0              7.0  0.0001  \n",
            "1496              4.0              5.0  0.0001  \n",
            "1497              1.0              1.0  0.0001  \n",
            "1498              2.0              3.0  0.0001  \n",
            "1499              0.0              0.0  0.0001  \n",
            "\n",
            "[1500 rows x 9 columns]\n",
            "Temp: 0.9707516339869281\n",
            "   precision  accuracy    recall  f1_score    duration  std  specificity\n",
            "0   0.970752    0.9625  0.970833  0.970273  548.003799  0.0     0.992059\n",
            "\t\t\t\tDONE\n",
            "\t\titer 5\n",
            "\t\t\tdataset_name:  AllCandidas\n",
            "valor de x_train no prepare data [[1.993e+04 5.877e+04 1.544e+04 ... 1.188e+03 4.239e+03 4.000e+00]\n",
            " [8.122e+04 7.305e+03 6.886e+03 ... 1.055e+04 7.302e+03 4.000e+00]\n",
            " [8.223e+04 7.305e+03 6.032e+03 ... 1.834e+04 7.841e+03 6.000e+00]\n",
            " ...\n",
            " [2.606e+04 4.686e+04 2.178e+04 ... 2.586e+03 5.592e+03 4.000e+00]\n",
            " [3.245e+04 4.572e+04 2.271e+04 ... 2.613e+03 5.596e+03 5.000e+00]\n",
            " [6.787e+04 1.842e+04 2.108e+04 ... 1.091e+04 6.971e+03 2.000e+00]]\n",
            "valor de y_train no prepare data [1. 6. 1. 2. 5. 1. 2. 2. 1. 2. 4. 5. 3. 1. 3. 5. 2. 5. 1. 6. 2. 6. 1. 5.\n",
            " 1. 2. 2. 6. 6. 5. 2. 1. 5. 4. 1. 1. 1. 6. 1. 1. 5. 6. 1. 2. 6. 4. 2. 2.\n",
            " 1. 6. 5. 5. 5. 6. 5. 2. 6. 5. 2. 2. 6. 6. 6. 2. 4. 5. 5. 3. 6. 4. 2. 1.\n",
            " 5. 5. 1. 6. 5. 5. 2. 2. 1. 1. 1. 4. 6. 1. 5. 5. 4. 5. 4. 2. 2. 6. 4. 5.\n",
            " 2. 4. 5. 3. 2. 6. 5. 2. 1. 5. 6. 2. 6. 6. 4. 5. 6. 5. 5. 6. 2. 4. 2. 2.\n",
            " 1. 3. 1. 2. 6. 2. 6. 5. 5. 6. 5. 6. 6. 3. 3. 4. 5. 2. 6. 2. 6. 2. 2. 4.\n",
            " 5. 4. 6. 6. 1. 6. 4. 2. 5. 5. 5. 1. 5. 6. 1. 5. 6. 1. 3. 3. 1. 6. 3. 1.\n",
            " 6. 4. 2. 2. 2. 1. 6. 6. 4. 2. 2. 2. 1. 2. 4. 6. 3. 1. 2. 1. 6. 2. 6. 1.\n",
            " 5. 2. 5. 1. 5. 1. 5. 1. 5. 1. 3. 3. 2. 1. 2. 1. 6. 4. 1. 1. 6. 2. 6. 2.\n",
            " 2. 2. 6. 6. 1. 5. 3. 6. 2. 1. 2. 1. 6. 5. 6. 6. 2. 4. 1. 3. 5. 6.]\n",
            "valor de y_val no prepare data [6. 3. 2. 2. 2. 2. 6. 2. 5. 1. 2. 3. 2. 2. 1. 2. 5. 2. 2. 2. 1. 1. 1. 2.\n",
            " 5. 1. 6. 3. 2. 6. 2. 4. 1. 6. 6. 1. 6. 3. 6. 6. 6. 4. 6. 5. 1. 4. 2. 5.\n",
            " 2. 5. 3. 6. 2. 6. 3. 2. 3. 3. 3. 6. 5. 4. 1. 5. 2. 6. 6. 1. 6. 6. 2. 6.\n",
            " 4. 6. 1. 3. 5. 6. 2.]\n",
            "Dentro do FitModel\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f14db4b7790> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 1s 26ms/step\n",
            "y_pred before save =  \n",
            " [[1.90561298e-06 9.99937892e-01 1.14504273e-05 3.83349143e-05\n",
            "  1.30346587e-06 9.01408475e-06]\n",
            " [4.72069905e-06 9.99815047e-01 3.39242360e-05 1.27615247e-04\n",
            "  3.62863398e-06 1.51179975e-05]\n",
            " [4.05410425e-08 3.83580773e-05 9.99907851e-01 3.17132908e-05\n",
            "  2.06688073e-05 1.37592906e-06]\n",
            " [3.62893161e-06 1.23307211e-04 9.55328214e-05 9.99683380e-01\n",
            "  9.29496091e-05 1.24245753e-06]\n",
            " [1.56073453e-04 9.01833409e-05 6.68245484e-05 1.57629638e-05\n",
            "  2.62332378e-05 9.99644876e-01]\n",
            " [3.38432845e-04 9.89714754e-05 8.94291770e-06 2.54060997e-05\n",
            "  2.41016722e-04 9.99287307e-01]\n",
            " [1.48153117e-06 9.99892592e-01 1.53112433e-05 8.16032407e-05\n",
            "  6.87638567e-06 2.15745172e-06]\n",
            " [1.80876697e-04 1.20474579e-04 1.16146788e-04 2.17194811e-05\n",
            "  2.81521898e-05 9.99532700e-01]\n",
            " [9.99861956e-01 5.14907661e-05 1.09558513e-08 2.11986588e-07\n",
            "  7.53469576e-05 1.09888924e-05]\n",
            " [2.59358046e-07 9.99998927e-01 1.92486493e-09 4.08559551e-08\n",
            "  4.52082389e-08 8.26736027e-07]\n",
            " [3.30663534e-06 5.33802377e-05 1.81143754e-04 9.99685287e-01\n",
            "  7.56892478e-05 1.13505394e-06]\n",
            " [1.78818675e-06 9.99991179e-01 4.82859193e-08 7.03613068e-07\n",
            "  2.40568784e-06 3.94911194e-06]\n",
            " [9.99949932e-01 1.61899661e-05 3.37846586e-08 1.29477121e-05\n",
            "  2.01411131e-05 6.98749488e-07]\n",
            " [1.79400027e-04 5.87828436e-06 9.97302323e-06 5.17582919e-07\n",
            "  9.99801815e-01 2.41762291e-06]\n",
            " [2.17135630e-06 9.99944448e-01 8.01172064e-06 3.54528820e-05\n",
            "  1.28108570e-06 8.56067618e-06]\n",
            " [4.02048259e-04 9.99579370e-01 2.45362730e-06 4.17858317e-08\n",
            "  1.24537678e-06 1.48093641e-05]\n",
            " [8.99297665e-05 3.32653872e-03 5.63674403e-05 9.96436834e-01\n",
            "  7.43380006e-05 1.58957700e-05]\n",
            " [1.45074964e-01 1.78591728e-01 2.56148178e-06 1.15533185e-05\n",
            "  3.56624550e-05 6.76283598e-01]\n",
            " [4.10532739e-05 9.99940157e-01 7.02642410e-07 4.00962836e-06\n",
            "  1.04340768e-06 1.30316248e-05]\n",
            " [9.99464333e-01 1.81787309e-05 5.22877542e-07 2.01647454e-05\n",
            "  4.94051143e-04 2.68876329e-06]\n",
            " [4.82311807e-05 2.08044480e-06 1.34903617e-04 2.01574512e-05\n",
            "  9.99792874e-01 1.80690131e-06]\n",
            " [3.31728043e-05 5.26185022e-06 2.74765480e-05 2.50306039e-06\n",
            "  9.99930859e-01 6.72991519e-07]\n",
            " [3.83198676e-06 1.44524689e-04 7.33205889e-05 9.99690890e-01\n",
            "  8.61339504e-05 1.31237402e-06]\n",
            " [1.49133397e-04 2.03209851e-07 3.33400948e-07 6.60908768e-07\n",
            "  9.99506593e-01 3.43091378e-04]\n",
            " [9.62134291e-05 7.35868753e-06 5.56773703e-05 9.33590036e-06\n",
            "  9.99828100e-01 3.31544493e-06]\n",
            " [9.99958873e-01 7.02052390e-08 5.60915980e-10 6.09905157e-07\n",
            "  4.01984071e-05 2.12201925e-07]\n",
            " [7.00342536e-01 5.51325618e-04 6.31485364e-07 4.77588173e-06\n",
            "  4.24884274e-06 2.99096346e-01]\n",
            " [9.99687195e-01 7.83288342e-05 6.38821064e-07 9.95463997e-05\n",
            "  1.31377819e-04 2.97410656e-06]\n",
            " [1.61432457e-04 7.05685583e-04 4.24415475e-06 9.38810263e-06\n",
            "  7.86398887e-05 9.99040663e-01]\n",
            " [2.90183928e-02 4.82846377e-03 5.03375418e-07 1.59629562e-05\n",
            "  7.29159638e-06 9.66129422e-01]\n",
            " [3.13446685e-06 8.59850715e-08 7.27679321e-07 1.62320532e-06\n",
            "  9.99796331e-01 1.98109803e-04]\n",
            " [1.44896752e-04 6.38203492e-05 4.47699631e-06 7.85611610e-06\n",
            "  1.27066469e-05 9.99766171e-01]\n",
            " [5.80263913e-05 1.57124869e-05 1.43777379e-05 6.52568815e-07\n",
            "  9.99908805e-01 2.43941486e-06]\n",
            " [7.34186688e-06 9.99368012e-01 1.23108533e-04 4.68383339e-04\n",
            "  1.73962635e-05 1.56797014e-05]\n",
            " [4.57537884e-04 7.25266509e-05 4.71638887e-05 2.12515788e-05\n",
            "  9.20946768e-05 9.99309421e-01]\n",
            " [6.00826024e-05 1.71017291e-06 1.14191840e-04 2.69652774e-05\n",
            "  9.99795258e-01 1.79362405e-06]\n",
            " [4.80651797e-05 8.29537657e-06 2.89455365e-05 1.19954848e-06\n",
            "  9.99910951e-01 2.44428929e-06]\n",
            " [3.71416733e-02 2.88071716e-03 4.24817614e-07 1.54583850e-05\n",
            "  5.46703359e-06 9.59956229e-01]\n",
            " [1.10048049e-07 1.86582092e-05 9.99869943e-01 5.21128495e-05\n",
            "  5.74518162e-05 1.75685386e-06]\n",
            " [4.76546340e-08 5.32776248e-05 9.99882936e-01 4.08534943e-05\n",
            "  2.13020758e-05 1.58474961e-06]\n",
            " [9.66923416e-01 9.74143273e-04 6.60659623e-07 7.37372659e-07\n",
            "  3.96814494e-06 3.20970602e-02]\n",
            " [2.30280595e-04 4.63116594e-05 4.71747953e-05 6.10152210e-06\n",
            "  9.99662519e-01 7.56853115e-06]\n",
            " [2.80644053e-05 9.99969482e-01 8.41468122e-08 4.14216714e-07\n",
            "  2.71854447e-07 1.73599574e-06]\n",
            " [4.58097093e-05 5.16604723e-06 1.56880833e-06 1.02003537e-06\n",
            "  9.99910355e-01 3.61709972e-05]\n",
            " [1.35659286e-06 9.99988556e-01 1.55185500e-08 1.91519362e-07\n",
            "  1.86107101e-07 9.69947359e-06]\n",
            " [9.99994993e-01 9.68764198e-07 3.12081277e-10 7.90425947e-09\n",
            "  1.73020567e-06 2.33519745e-06]\n",
            " [1.84300632e-04 1.61161481e-07 2.52496790e-07 5.37402684e-07\n",
            "  9.99402761e-01 4.11929970e-04]\n",
            " [9.99999285e-01 7.59014469e-08 2.68374836e-11 5.75823667e-10\n",
            "  4.97206436e-08 5.61739341e-07]\n",
            " [5.81798849e-06 9.99974132e-01 7.95375229e-07 3.53020869e-06\n",
            "  6.17368869e-07 1.50614260e-05]\n",
            " [3.42924523e-06 9.99292135e-01 4.11458808e-04 1.69515173e-04\n",
            "  1.15300274e-04 8.13549468e-06]\n",
            " [1.11405393e-02 9.70208943e-01 6.91514290e-10 2.08433264e-07\n",
            "  1.86502729e-02 2.13231175e-08]\n",
            " [8.52002700e-08 1.69095292e-04 9.99746263e-01 3.38087011e-05\n",
            "  4.73781765e-05 3.23425093e-06]\n",
            " [3.06949858e-07 9.99999642e-01 3.66297487e-13 3.32209676e-10\n",
            "  5.80047441e-08 1.88811575e-12]\n",
            " [1.09042114e-04 3.57454301e-05 1.38079747e-06 5.38591485e-06\n",
            "  5.38721157e-04 9.99309778e-01]\n",
            " [9.99562323e-01 1.17470809e-05 3.40264620e-07 1.58917846e-05\n",
            "  4.07587679e-04 2.05887773e-06]\n",
            " [1.11060663e-05 9.99950409e-01 2.11181123e-06 9.10273593e-06\n",
            "  1.74999525e-06 2.55127525e-05]\n",
            " [6.67601591e-04 7.47488288e-04 1.56195019e-05 4.70158702e-05\n",
            "  2.53044884e-04 9.98269200e-01]\n",
            " [2.78421164e-01 8.01641785e-04 1.56435510e-06 5.91710830e-07\n",
            "  5.74443175e-06 7.20769286e-01]\n",
            " [9.99662161e-01 3.35001503e-04 2.84034823e-10 4.58905198e-08\n",
            "  2.84141584e-06 4.38459544e-08]\n",
            " [1.06013875e-04 8.86378621e-06 6.03639419e-05 1.10688443e-05\n",
            "  9.99810040e-01 3.68745668e-06]\n",
            " [3.89790785e-06 1.61513629e-08 7.46261541e-09 7.27091409e-09\n",
            "  1.82617921e-08 9.99996066e-01]\n",
            " [6.70806694e-05 2.28469503e-06 6.81820165e-05 1.45538697e-05\n",
            "  9.99846220e-01 1.61621642e-06]\n",
            " [6.86941785e-05 2.46962577e-06 1.94103268e-04 3.53577634e-05\n",
            "  9.99696612e-01 2.69743555e-06]\n",
            " [9.99932051e-01 7.20812068e-07 1.13160681e-08 1.80799066e-06\n",
            "  7.68572534e-07 6.46816843e-05]\n",
            " [6.38689089e-05 2.76286642e-06 2.43467322e-04 3.86980209e-05\n",
            "  9.99648333e-01 2.83544296e-06]\n",
            " [4.86523815e-04 6.70769878e-05 4.54481960e-05 2.11370261e-05\n",
            "  8.42253867e-05 9.99295592e-01]\n",
            " [6.94261551e-01 3.79597041e-04 7.94085224e-07 4.65224417e-07\n",
            "  6.48309788e-06 3.05351168e-01]\n",
            " [8.54511454e-05 9.20980256e-06 7.86569726e-05 1.03209059e-05\n",
            "  9.99812543e-01 3.86833199e-06]\n",
            " [3.77936754e-04 4.32146771e-05 5.93067307e-05 1.81574069e-05\n",
            "  9.99491215e-01 1.01150954e-05]\n",
            " [9.99886155e-01 3.03132620e-05 1.48623030e-07 2.75833827e-05\n",
            "  5.45242910e-05 1.29701004e-06]\n",
            " [9.02892953e-06 7.92015840e-08 3.90262016e-07 7.69251926e-07\n",
            "  9.99896288e-01 9.34667987e-05]\n",
            " [1.13729093e-05 9.99968529e-01 6.15224224e-07 3.12562088e-06\n",
            "  6.50665129e-07 1.58502808e-05]\n",
            " [9.99737561e-01 1.57098782e-06 9.00439190e-08 8.54425798e-06\n",
            "  1.78180999e-04 7.41191689e-05]\n",
            " [9.99608219e-01 3.87950684e-04 3.06126291e-10 6.14306401e-08\n",
            "  3.71139913e-06 2.80198371e-08]\n",
            " [1.14083186e-05 9.99411464e-01 7.26380968e-05 4.72521147e-04\n",
            "  9.68286258e-06 2.22409435e-05]\n",
            " [2.92469980e-04 1.43113706e-04 5.46047477e-06 1.26433752e-05\n",
            "  1.30903181e-05 9.99533176e-01]\n",
            " [1.75678224e-06 9.99964595e-01 4.05041646e-06 2.16873996e-05\n",
            "  8.68458528e-07 6.95935660e-06]\n",
            " [5.90722084e-06 9.99981165e-01 3.20344427e-08 4.13059837e-07\n",
            "  1.50406620e-07 1.23023747e-05]\n",
            " [7.46601820e-01 4.29941865e-05 5.97212102e-06 1.38380536e-04\n",
            "  2.52294004e-01 9.16847261e-04]\n",
            " [3.70670051e-07 2.65736398e-05 9.99657989e-01 8.95849153e-05\n",
            "  2.21877082e-04 3.58636385e-06]]\n",
            "Histórico\n",
            "          loss  accuracy    recall  precision  true_positives  true_negatives  \\\n",
            "0     1.717338  0.352941  0.121849   0.508772            29.0          1162.0   \n",
            "1     1.161355  0.546219  0.235294   0.767123            56.0          1173.0   \n",
            "2     1.009216  0.592437  0.436975   0.622755           104.0          1127.0   \n",
            "3     0.947002  0.621849  0.407563   0.746154            97.0          1157.0   \n",
            "4     0.900535  0.621849  0.516807   0.683333           123.0          1133.0   \n",
            "...        ...       ...       ...        ...             ...             ...   \n",
            "1495  0.023856  0.991597  0.991597   0.991597           236.0          1188.0   \n",
            "1496  0.006624  0.995798  0.995798   0.995798           237.0          1189.0   \n",
            "1497  0.010941  0.995798  0.995798   0.995798           237.0          1189.0   \n",
            "1498  0.027619  0.991597  0.991597   0.991597           236.0          1188.0   \n",
            "1499  0.004482  1.000000  1.000000   1.000000           238.0          1190.0   \n",
            "\n",
            "      false_positives  false_negatives      lr  \n",
            "0                28.0            209.0  0.0010  \n",
            "1                17.0            182.0  0.0010  \n",
            "2                63.0            134.0  0.0010  \n",
            "3                33.0            141.0  0.0010  \n",
            "4                57.0            115.0  0.0010  \n",
            "...               ...              ...     ...  \n",
            "1495              2.0              2.0  0.0001  \n",
            "1496              1.0              1.0  0.0001  \n",
            "1497              1.0              1.0  0.0001  \n",
            "1498              2.0              2.0  0.0001  \n",
            "1499              0.0              0.0  0.0001  \n",
            "\n",
            "[1500 rows x 9 columns]\n",
            "Temp: 0.9511437908496733\n",
            "   precision  accuracy  recall  f1_score    duration  std  specificity\n",
            "0   0.951144    0.9375    0.95  0.950071  545.671806  0.0     0.986851\n",
            "\t\t\t\tDONE\n",
            "\t\titer 6\n",
            "\t\t\tdataset_name:  AllCandidas\n",
            "valor de x_train no prepare data [[1.993e+04 5.877e+04 1.544e+04 ... 1.188e+03 4.239e+03 4.000e+00]\n",
            " [8.122e+04 7.305e+03 6.886e+03 ... 1.055e+04 7.302e+03 4.000e+00]\n",
            " [8.223e+04 7.305e+03 6.032e+03 ... 1.834e+04 7.841e+03 6.000e+00]\n",
            " ...\n",
            " [2.606e+04 4.686e+04 2.178e+04 ... 2.586e+03 5.592e+03 4.000e+00]\n",
            " [3.245e+04 4.572e+04 2.271e+04 ... 2.613e+03 5.596e+03 5.000e+00]\n",
            " [6.787e+04 1.842e+04 2.108e+04 ... 1.091e+04 6.971e+03 2.000e+00]]\n",
            "valor de y_train no prepare data [1. 6. 1. 2. 5. 1. 2. 2. 1. 2. 4. 5. 3. 1. 3. 5. 2. 5. 1. 6. 2. 6. 1. 5.\n",
            " 1. 2. 2. 6. 6. 5. 2. 1. 5. 4. 1. 1. 1. 6. 1. 1. 5. 6. 1. 2. 6. 4. 2. 2.\n",
            " 1. 6. 5. 5. 5. 6. 5. 2. 6. 5. 2. 2. 6. 6. 6. 2. 4. 5. 5. 3. 6. 4. 2. 1.\n",
            " 5. 5. 1. 6. 5. 5. 2. 2. 1. 1. 1. 4. 6. 1. 5. 5. 4. 5. 4. 2. 2. 6. 4. 5.\n",
            " 2. 4. 5. 3. 2. 6. 5. 2. 1. 5. 6. 2. 6. 6. 4. 5. 6. 5. 5. 6. 2. 4. 2. 2.\n",
            " 1. 3. 1. 2. 6. 2. 6. 5. 5. 6. 5. 6. 6. 3. 3. 4. 5. 2. 6. 2. 6. 2. 2. 4.\n",
            " 5. 4. 6. 6. 1. 6. 4. 2. 5. 5. 5. 1. 5. 6. 1. 5. 6. 1. 3. 3. 1. 6. 3. 1.\n",
            " 6. 4. 2. 2. 2. 1. 6. 6. 4. 2. 2. 2. 1. 2. 4. 6. 3. 1. 2. 1. 6. 2. 6. 1.\n",
            " 5. 2. 5. 1. 5. 1. 5. 1. 5. 1. 3. 3. 2. 1. 2. 1. 6. 4. 1. 1. 6. 2. 6. 2.\n",
            " 2. 2. 6. 6. 1. 5. 3. 6. 2. 1. 2. 1. 6. 5. 6. 6. 2. 4. 1. 3. 5. 6.]\n",
            "valor de y_val no prepare data [6. 3. 2. 2. 2. 2. 6. 2. 5. 1. 2. 3. 2. 2. 1. 2. 5. 2. 2. 2. 1. 1. 1. 2.\n",
            " 5. 1. 6. 3. 2. 6. 2. 4. 1. 6. 6. 1. 6. 3. 6. 6. 6. 4. 6. 5. 1. 4. 2. 5.\n",
            " 2. 5. 3. 6. 2. 6. 3. 2. 3. 3. 3. 6. 5. 4. 1. 5. 2. 6. 6. 1. 6. 6. 2. 6.\n",
            " 4. 6. 1. 3. 5. 6. 2.]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-15-c033a5082e59>:21: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  df_best_model = pd.DataFrame(data=np.zeros((1, 6), dtype=np.float), index=[0],\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dentro do FitModel\n"
          ]
        }
      ],
      "source": [
        "# run nb_iter_ iterations of Inception on the whole TSC archive\n",
        "classifier_name = 'inception'\n",
        "#archive_name = ARCHIVE_NAMES[0]\n",
        "archive_name = UNIVARIATE_ARCHIVE_NAMES[0]\n",
        "nb_iter_ = 10\n",
        "\n",
        "datasets_dict = read_all_datasets(root_dir, archive_name)\n",
        "\n",
        "for iter in range(nb_iter_):\n",
        "    print('\\t\\titer', iter)\n",
        "\n",
        "    trr = ''\n",
        "    if iter != 0:\n",
        "        trr = '_itr_' + str(iter)\n",
        "\n",
        "    tmp_output_directory = root_dir + '/results/' + classifier_name + '/' + archive_name + trr + '/'\n",
        "\n",
        "    for dataset_name in dataset_names_for_archive[archive_name]:\n",
        "        print('\\t\\t\\tdataset_name: ', dataset_name)\n",
        "\n",
        "        x_train, y_train, x_test, y_test, x_test, x_val, y_val, y_true, nb_classes, y_true_train, enc = prepare_data()\n",
        "        # print(f\"Valor de y_train: {y_train}\")\n",
        "        # print(f\"Valor de x_train: {x_train}\")\n",
        "\n",
        "\n",
        "        output_directory = tmp_output_directory + dataset_name + '/'\n",
        "\n",
        "        temp_output_directory = create_directory(output_directory)\n",
        "\n",
        "        if temp_output_directory is None:\n",
        "            print('Already_done', tmp_output_directory, dataset_name)\n",
        "            continue\n",
        "\n",
        "        try:\n",
        "            with tf.device('/device:GPU:0'):\n",
        "                fit_classifier()\n",
        "                print('\\t\\t\\t\\tDONE')\n",
        "        except:\n",
        "            fit_classifier()\n",
        "            print('\\t\\t\\t\\tDONE')\n",
        "\n",
        "            # the creation of this directory means\n",
        "            create_directory(output_directory + '/DONE')\n",
        "\n",
        "#res['std'] = std\n",
        "# run the ensembling of these iterations of Inception\n",
        "# classifier_name = 'nne'\n",
        "\n",
        "# datasets_dict = read_all_datasets(root_dir, archive_name)\n",
        "\n",
        "# tmp_output_directory = root_dir + '/results/' + classifier_name + '/' + archive_name + '/'\n",
        "\n",
        "# for dataset_name in dataset_names_for_archive[archive_name]:\n",
        "#     print('\\t\\t\\tdataset_name: ', dataset_name)\n",
        "\n",
        "#     x_train, y_train, x_test, y_test, y_true, nb_classes, y_true_train, enc = prepare_data()\n",
        "\n",
        "#     output_directory = tmp_output_directory + dataset_name + '/'\n",
        "#     with tf.device('/device:GPU:0'):\n",
        "#         fit_classifier()\n",
        "\n",
        "#     print('\\t\\t\\t\\tDONE')\n",
        "\n",
        "std = np.std(accuracy)\n",
        "root_dir = '/content/drive/MyDrive/Colab Notebooks/Candidas'\n",
        "\n",
        "clf_name = 'inception'\n",
        "\n",
        "path = '/'\n",
        "\n",
        "def update_metrics(root_dir,path ,archive_name, dataset_name, std):\n",
        "    output_dir = root_dir + path + archive_name + '/' \\\n",
        "                            + dataset_name + '/' + 'df_metrics.csv'\n",
        "    #print(output_dir)\n",
        "    #print('j = ',j,'i = ',i)\n",
        "    if os.path.exists(output_dir):\n",
        "        df_metrics = pd.read_csv(output_dir)\n",
        "        df_metrics['std'] = std\n",
        "        df_metrics.to_csv(output_dir + 'df_metrics_val.csv', index=False)\n",
        "    return df_metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ORgKD2Y8n1W2"
      },
      "outputs": [],
      "source": [
        "\n",
        "def gen_results_csv(clf_name, path, root_dir):\n",
        "\n",
        "    ARCHIVE_NAMES = ['TSC', 'TSC_itr_1', 'TSC_itr_2', 'TSC_itr_3', 'TSC_itr_4', 'TSC_itr_5',\n",
        "                     'TSC_itr_6', 'TSC_itr_7', 'TSC_itr_8', 'TSC_itr_9'] \n",
        "    \n",
        "    DATASET_NAME = ['AllCandidas'] \n",
        "   \n",
        "    res1 = np.zeros((10, 3))\n",
        "    \n",
        "    res1 = pd.DataFrame(res1)\n",
        "    \n",
        "    res1 = res1.astype(object)\n",
        "    \n",
        "    nomes = ['classifier_name', 'archive_name', 'dataset_name']\n",
        "    res1.columns=nomes\n",
        "    \n",
        "    res2 = np.zeros((10, 9))\n",
        "    \n",
        "    i = 0\n",
        "    j = 0\n",
        "    for archive_name in ARCHIVE_NAMES:\n",
        "    \n",
        "        o = 0\n",
        "        for dataset_name in DATASET_NAME:\n",
        "    \n",
        "            output_dir = root_dir + path + archive_name + '/' \\\n",
        "                         + dataset_name + '/' + 'df_metrics_val.csv'\n",
        "            #print(output_dir)\n",
        "            print('j = ',j,'i = ',i)            \n",
        "            if not os.path.exists(output_dir):\n",
        "                print(f\"Path {output_dir} do not exists\")\n",
        "                continue\n",
        "            df_metrics = pd.read_csv(output_dir)\n",
        "            print(f\"Hehehe {df_metrics}\")\n",
        "            res1['classifier_name'][j] = clf_name\n",
        "            res1['archive_name'][j] = archive_name\n",
        "            res1['dataset_name'][j] = dataset_name\n",
        "            res2[j,0] = j\n",
        "            res2[j,1] = o\n",
        "            res2[j,2] = i\n",
        "            res2[j,3] = df_metrics['precision']\n",
        "            res2[j,4] = df_metrics['accuracy']\n",
        "            res2[j,5] = df_metrics['recall']\n",
        "            res2[j,6] = df_metrics['f1_score']\n",
        "            res2[j,7] = np.std(df_metrics['accuracy'])\n",
        "            res2[j,8] = df_metrics['duration']\n",
        "            \n",
        "            o += 1\n",
        "            j += 1\n",
        "        i += 1\n",
        "    \n",
        "    \n",
        "    res2 = pd.DataFrame(res2)\n",
        "    #print(res2)\n",
        "    nomes = ['ord1', 'ord2', 'iteration', 'precision', 'accuracy','recall','f1_score','std','duration']\n",
        "    res2.columns=nomes\n",
        "    \n",
        "    \n",
        "    res = pd.concat([res1, res2], ignore_index=True, axis=1)\n",
        "    nomes = ['classifier_name', 'archive_name', 'dataset_name','ord1', 'ord2',\n",
        "             'iteration', 'precision', 'accuracy', 'recall','f1_score','std', 'duration']\n",
        "    res.columns=nomes\n",
        "    \n",
        "    res = res.sort_values(by=['ord2', 'ord1'])\n",
        "    \n",
        "    return res\n",
        "\n",
        "\n",
        "root_dir = '/content/drive/MyDrive/Colab Notebooks/Candidas/results/inception'\n",
        "\n",
        "clf_name = 'inception'\n",
        "\n",
        "path = '/'\n",
        "\n",
        "res = gen_results_csv(clf_name, path, root_dir)\n",
        "\n",
        "print(res)\n",
        "\n",
        "arq = clf_name + '.csv'\n",
        "filepath = root_dir + path + arq\n",
        "res.to_csv(filepath, index=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oB8eGmJ2tQ1K"
      },
      "outputs": [],
      "source": [
        "from pickle import dump\n",
        "def save_results(df_to_save, name, train_val_test):\n",
        "    print(\"Saving metrics...\")\n",
        "    print(f\"Df accuracy: {df_to_save}\")\n",
        "    df_to_save.to_csv(root_dir+ '/df_'+name+'_'+train_val_test+'2.csv', index=False)\n",
        "    print(\"Accuracy of models:\")\n",
        "    print(df_to_save)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pOJuNN0xtJYO"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "import time\n",
        "def test_final_model(x_val, y_val, model):\n",
        "    scoring = ['accuracy','precision_macro', 'recall_macro','f1_macro']\n",
        "#     for name, model in models:\n",
        "        # df_test = cross_validate(model, X_test, y_test, cv=kf, scoring=scoring\n",
        "        #                          , return_train_score=True)\n",
        "#         print(f'Model in test: {name}')\n",
        "\n",
        "    df_test = pd.DataFrame([], columns=['accuracy','recall','precision','f1_score','specificity','testTime'])\n",
        "    \n",
        "    start_time = time.time()\n",
        "    y_pred = model.predict(x_val, batch_size=1500)\n",
        "    time_prediction = time.time()-start_time\n",
        "\n",
        "    y_pred = np.argmax(y_pred, axis=1)\n",
        "    onehot_encoder = OneHotEncoder(sparse=False)\n",
        "    y_pred = y_pred.reshape(len(y_pred), 1)\n",
        "    y_pred = onehot_encoder.fit_transform(y_pred)\n",
        "    print(\"Y pred ---- \")\n",
        "    print(y_pred)\n",
        "    print(\"Y val\")\n",
        "    print(y_val)\n",
        "    accuracy  =  accuracy_score(y_val, y_pred)\n",
        "    recall    =  recall_score(y_val, y_pred, average='macro')\n",
        "    precision =  precision_score(y_val, y_pred, average='macro')\n",
        "    f1  =  f1_score(y_val, y_pred, average='macro')\n",
        "    specificity = specificity_score(y_val, y_pred)\n",
        "    print(f\"accuracy: {accuracy}, recall: {recall}, precision: {precision},f1: {f1} \")\n",
        "    df_test.at[0, 'accuracy'] = accuracy\n",
        "    df_test.at[0, 'recall'] = recall\n",
        "    df_test.at[0,'precision'] = precision\n",
        "    df_test.at[0,'f1_score'] = f1\n",
        "    df_test.at[0,'specificity'] = specificity\n",
        "    df_test.at[0,'testTime'] =  time_prediction\n",
        "    print(df_test.keys())\n",
        "    save_results(df_test,\"INCEPTION\", 'test')\n",
        "    print(\"Finished test!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SehDUvqF9Oie"
      },
      "outputs": [],
      "source": [
        "archive_name = 'TSC_itr_3'\n",
        "tmp_output_directory = root_dir + '/'+ archive_name + '/'\n",
        "output_directory = tmp_output_directory + dataset_name + '/'\n",
        "print(tmp_output_directory)\n",
        "# dataset = np.load(output_directory+'/y_pred'+'.npy', encoding='bytes')\n",
        "# dataset"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(x_val.shape)\n",
        "print(y_val.shape)"
      ],
      "metadata": {
        "id": "OVn0WmTtW9a4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qAtP3OMKY15H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dr485WvaZtNC"
      },
      "outputs": [],
      "source": [
        "model_path = output_directory + 'best_model.hdf5'\n",
        "model = keras.models.load_model(model_path)\n",
        "test_final_model(x_val, y_val, model)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}